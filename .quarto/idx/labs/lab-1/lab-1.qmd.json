{"title":"Assignment 1: Census Data Quality for Policy Decisions","markdown":{"yaml":{"title":"Assignment 1: Census Data Quality for Policy Decisions","subtitle":"Evaluating Data Reliability for Algorithmic Decision-Making","author":"Tessa Vu","date":"2025-09-08","format":{"html":{"code-fold":false,"toc":true,"toc-location":"left","theme":"lux"}},"execute":{"warning":false,"message":false}},"headingText":"Assignment Overview","containsRefs":false,"markdown":"\n\n\n## Scenario\n\nYou are a data analyst for the **Utah Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\n\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n## Learning Objectives\n\n- Apply dplyr functions to real census data for policy analysis\n- Evaluate data quality using margins of error \n- Connect technical analysis to algorithmic decision-making\n- Identify potential equity implications of data reliability issues\n- Create professional documentation for policy stakeholders\n\n## Submission Instructions\n\n**Submit by posting your updated portfolio link on Canvas.** Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/`\n\nMake sure to update your `_quarto.yml` navigation to include this assignment under an \"Assignments\" menu.\n\n# Part 1: Portfolio Integration\n\nCreate this assignment in your portfolio repository under an `assignments/assignment_1/` folder structure. Update your navigation menu to include:\n\n```\n- text: Assignments\n  menu:\n    - href: assignments/assignment_1/your_file_name.qmd\n      text: \"Assignment 1: Census Data Exploration\"\n```\nIf there is a special character like comma, you need use double quote mark so that the quarto can identify this as text\n\n# Setup\n\n```{r setup}\n# Load required packages (hint: you need tidycensus, tidyverse, and knitr)\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Set your Census API key\ncensus_api_key(\"3aaee31789e10b674a531e9f236c35d5394b19ed\")\n\n# Choose your state for analysis - assign it to a variable called my_state\nmy_state = \"Utah\"\n```\n\n**State Selection:** I've chosen **Utah** for this analysis because: It's my hometown and I grew up around Salt Lake valley area in different neighborhoods and would like to explore the data behind my memories and maybe how things have changed since I was last living there around 3 years ago.\n\n# Part 2: County-Level Resource Assessment\n\n## 2.1 Data Retrieval\n\n**Your Task:** Use `get_acs()` to retrieve county-level data for your chosen state.\n\n**Requirements:**\n- Geography: county level\n- Variables: median household income (B19013_001) and total population (B01003_001)  \n- Year: 2022\n- Survey: acs5\n- Output format: wide\n\n**Hint:** Remember to give your variables descriptive names using the `variables = c(name = \"code\")` syntax.\n\n```{r county-data}\n# Write your get_acs() code here\nutah_reliability <- get_acs(\n  geography = \"county\",\n  state = my_state,\n  # Median household income and total population.\n  variables = c(median_inc = \"B19013_001\", total_pop = \"B01003_001\"),\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\nutah_reliability <- mutate(utah_reliability, NAME = str_remove(NAME, \" County, Utah\"))\n\n# Display the first few rows\nglimpse(utah_reliability)\n```\n\n## 2.2 Data Quality Assessment\n\n**Your Task:** Calculate margin of error percentages and create reliability categories.\n\n**Requirements:**\n- Calculate MOE percentage: (margin of error / estimate) * 100\n- Create reliability categories:\n  - High Confidence: MOE < 5%\n  - Moderate Confidence: MOE 5-10%  \n  - Low Confidence: MOE > 10%\n- Create a flag for unreliable estimates (MOE > 10%)\n\n**Hint:** Use `mutate()` with `case_when()` for the categories.\n\n```{r income-reliability}\n# Calculate MOE percentage and reliability categories using mutate()\nutah_reliability <- mutate(utah_reliability, MOE_percent = (median_incM / median_incE) * 100) %>%\n                mutate(utah_reliability, reliability_cat =\n                         case_when(\n                           MOE_percent < 5 ~ \"High Confidence\",\n                           MOE_percent <= 10 ~ \"Moderate Confidence\",\n                           MOE_percent > 10 ~ \"Low Confidence\"\n                           )) %>%\n                mutate(utah_reliability, low_flag = reliability_cat == \"Low Confidence\")\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages\n\ncount_summary <- utah_reliability %>%\n  group_by(reliability_cat) %>%\n  summarize(frequency = n()) %>%\n  mutate(frequency = frequency) %>%\n  mutate(percent_counties = frequency / sum(frequency))\n\ncount_summary\n```\n\n## 2.3 High Uncertainty Counties\n\n**Your Task:** Identify the 5 counties with the highest MOE percentages.\n\n**Requirements:**\n- Sort by MOE percentage (highest first)\n- Select the top 5 counties\n- Display: county name, median income, margin of error, MOE percentage, reliability category\n- Format as a professional table using `kable()`\n\n**Hint:** Use `arrange()`, `slice()`, and `select()` functions.\n\n```{r high-uncertainty}\n# Create table of top 5 counties by MOE percentage\ntop_5 <- data.frame()\n\ntop_5 <- utah_reliability %>%\n  arrange(desc(MOE_percent)) %>%\n  slice(0:5) %>%\n  select(2:8)\n\n# Format as table with kable() - include appropriate column names and caption\nkable(\n  top_5,\n  col.names = c(\"County\", \"Median Income\", \"Median Income MOE\", \"Total Population\", \"Total Population MOE\", \"Percent MOE\", \"MOE Confidence\"),\n  digit = 2,\n  caption = \"<b>TOP 5 UTAH COUNTIES: HIGHEST MEDIAN INCOME MARGIN-OF-ERROR</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n  \n```\n\n**Data Quality Commentary:**\n\nThe top five counties with the highest MOEs are ruralâ€”Piute, Wayne, Daggett, and Kane counties lack a major interstate highway in a state with cities that rely on car-transport within urban areas as well as within the vast swaths of undeveloped desert land. Beaver county at fifth does have the I-15 freeway. Another factor is the environmental topography that could influence towns' infrastructure expansion as well as travel, all five counties' are mountainous regions for the majority of their landscape, making it difficult and expensive to develop.\n\n# Part 3: Neighborhood-Level Analysis\n\n## 3.1 Focus Area Selection\n\n**Your Task:** Select 2-3 counties from your reliability analysis for detailed tract-level study.\n\n**Strategy:** Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n```{r select-counties}\n# Use filter() to select 2-3 counties from your utah_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties <- utah_reliability %>%\n  filter(NAME == \"Salt Lake\" | NAME == \"Morgan\" | NAME == \"Piute\") %>%\n  arrange(MOE_percent)\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\nkable(\n  selected_counties[c(\"GEOID\", \"NAME\", \"median_incE\", \"MOE_percent\", \"reliability_cat\")],\n  col.names = c(\"GEOID\", \"County\", \"Median Income\", \"MOE Percentage\", \"MOE Confidence\"),\n  digit = 2,\n  caption = \"<b>SELECTED UTAH COUNTIES</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n```\n\n**Comment on the output:** This table output shows Salt Lake, Morgan, and Piute counties, which have high, moderate, and low confidence, respectively. Salt Lake has a 1.17% MOE percentage and Morgan has a 7.78% MOE percentage, Piute has a significant jump from Morgan by 29.33% units at 37.11%. Salt Lake and Morgan are counties that are actually adjacent to one another, whereas Piute is in central, rural Utah.\n\n## 3.2 Tract-Level Demographics\n\n**Your Task:** Get demographic data for census tracts in your selected counties.\n\n**Requirements:**\n- Geography: tract level\n- Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001)\n- Use the same state and year as before\n- Output format: wide\n- **Challenge:** You'll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n```{r tract-demographics}\n# Define your race/ethnicity variables with descriptive names\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\ntract_level <- get_acs(\n  geography = \"tract\",\n  state = my_state,\n  # Median household income and total population.\n  variables = c(white = \"B03002_003\", black = \"B03002_004\", hispanic = \"B03002_012\", total = \"B03002_001\"),\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n) %>%\n  filter(str_detect(GEOID, \"^49035\") | str_detect(GEOID, \"^49029\") | str_detect(GEOID, \"^49031\"))\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\ntract_level <- tract_level %>%\n  mutate(\n    \"White Percentage\" = (whiteE / totalE) * 100,\n    \"Black Percentage\" = (blackE / totalE) * 100,\n    \"Hispanic Percentage\" = (hispanicE / totalE) * 100\n  )\n\n# Add readable tract and county name columns using str_extract() or similar\ntract_level <- tract_level %>%\n  separate(\n    col = NAME,\n    into = c(\"TRACT\", \"COUNTY\", \"STATE\"),\n    sep = \";\"\n  )\n\ntract_level\n  \n```\n\n## 3.3 Demographic Analysis\n\n**Your Task:** Analyze the demographic patterns in your selected areas.\n\n```{r demographic-analysis}\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\ntract_level <- tract_level %>%\n  arrange(desc(`Hispanic Percentage`))\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\ntract_level_summary <- tract_level %>%\n  group_by(COUNTY) %>%\n  summarize(\"Number of Tracts\" = n(),\n            \"White Average Percent\" = mean(`White Percentage`, na.rm = TRUE),\n            \"Black Average Percent\" = mean(`Black Percentage`, na.rm = TRUE),\n            \"Hispanic Average Percent\" = mean(`Hispanic Percentage`, na.rm = TRUE)\n            )\n\n# Create a nicely formatted table of your results using kable()\nkable(\n  tract_level_summary,\n  caption = \"<b>SELECTED UTAH COUNTIES: Average Racial Percents</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n```\n\n# Part 4: Comprehensive Data Quality Evaluation\n\n## 4.1 MOE Analysis for Demographic Variables\n\n**Your Task:** Examine margins of error for demographic variables to see if some communities have less reliable data.\n\n**Requirements:**\n- Calculate MOE percentages for each demographic variable\n- Flag tracts where any demographic variable has MOE > 15%\n- Create summary statistics\n\n```{r demographic-moe}\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\noptions(scipen = 999)\n\n# Avoid Inf values by changing 0 values to 0.01.\nMOE_percentages <- tract_level %>%\n  mutate(across(c(whiteM, whiteE, blackM, blackE, hispanicM, hispanicE),\n                ~ifelse(. == 0, 0.1, .)))\n\nMOE_percentages <- MOE_percentages %>%\n  mutate(\n    \"White MOE\" = (whiteM / whiteE) * 100,\n    \"Black MOE\" = (blackM / blackE) * 100,\n    \"Hispanic MOE\" = (hispanicM / hispanicE) * 100\n  )\n\n# Use logical operators (| for OR) in an ifelse() statement\nMOE_percentages <- MOE_percentages %>%\n  mutate(MOE_percentages,\n         \"MOE Flag\" = if_else(\n           `White MOE` > 15 | `Black MOE` > 15 | `Hispanic MOE` > 15, TRUE, FALSE\n         )\n  )\n\n# Create summary statistics showing how many tracts have data quality issues\ndata_quality_summary <- MOE_percentages %>%\n  group_by(COUNTY) %>%\n  summarize(\n    \"Number of Tracts\" = n(),\n    \"Data Quality Issues\" = sum(`MOE Flag`, na.rm = TRUE)\n    )\n\ndata_quality_summary\n\n```\n\n## 4.2 Pattern Analysis\n\n**Your Task:** Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n```{r pattern-analysis}\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n# Use group_by() and summarize() to create this comparison\n\nflagged_MOE <- MOE_percentages %>%\n  group_by(`MOE Flag`) %>%\n  summarize(\n    \"Avg White\" = mean(whiteE, na.rm = TRUE), \"Avg % White\" = mean(`White Percentage`, na.rm = TRUE),\n    \"Avg Black\" = mean(blackE, na.rm = TRUE), \"Avg % Black\" = mean(`Black Percentage`, na.rm = TRUE),\n    \"Avg Hispanic\" = mean(hispanicE, na.rm = TRUE), \"Avg % Hispanic\" = mean(`Hispanic Percentage`, na.rm = TRUE)\n    )\n\n# Create a professional table showing the patterns\nkable(\n  flagged_MOE,\n  digit = 2,\n  caption = \"<b>SALT LAKE, MORGAN, AND PIUTE COUNTIES: Average Population and Percents by Race</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n\n```\n\n```{r}\n# Check minimums.\nmin(MOE_percentages[[\"White MOE\"]])\nmin(MOE_percentages[[\"Black MOE\"]])\nmin(MOE_percentages[[\"Hispanic MOE\"]])\n\n# Flag tracts with MOES below 15%.\nlow_MOE <- MOE_percentages %>%\n  mutate(MOE_percentages,\n         \"Low MOE\" = if_else(\n           `White MOE` < 15 | `Black MOE` < 15 | `Hispanic MOE` < 15, TRUE, FALSE\n         )\n  )\n\n# Group low MOEs.\nlow_MOE_summary <- low_MOE %>%\n  group_by(`Low MOE`) %>%\n  summarize(\n    \"Avg White\" = mean(whiteE, na.rm = TRUE), \"Avg % White\" = mean(`White Percentage`, na.rm = TRUE),\n    \"Avg Black\" = mean(blackE, na.rm = TRUE), \"Avg % Black\" = mean(`Black Percentage`, na.rm = TRUE),\n    \"Avg Hispanic\" = mean(hispanicE, na.rm = TRUE), \"Avg % Hispanic\" = mean(`Hispanic Percentage`, na.rm = TRUE)\n    )\n  \nlow_MOE_summary\n\n```\n\n**Pattern Analysis:** All of the census tracts in Salt Lake, Morgan, and Piute counties had MOEs above 15%, and judging off of that it seems like the census had significant MOEs for the three races. However, when looking at the minimum MOE percentages, the white population's range starts at 6.31%, and Hispanic at 17.60% and Black at 54.39%, which are both substantial jumps from the white communities. Possible explanations might be due to redlining, and from anecdotal knowledge, the diversity in Salt Lake county tends to be clustered on the west side and periphery with higher Black, Hispanic, and Asian populations. Another explanation could be that the other counties are smaller and have a much larger white population.\n\n# Part 5: Policy Recommendations\n\n## 5.1 Analysis Integration and Professional Summary\n\n**Your Task:** Write an executive summary that integrates findings from all four analyses.\n\n**Executive Summary Requirements:**\n1. **Overall Pattern Identification**: What are the systematic patterns across all your analyses?\n2. **Equity Assessment**: Which communities face the greatest risk of algorithmic bias based on your findings?\n3. **Root Cause Analysis**: What underlying factors drive both data quality issues and bias risk?\n4. **Strategic Recommendations**: What should the Department implement to address these systematic issues?\n\n**Executive Summary:**\n\nLooking at the data without any geographic or chart visualization, it seems like many of the counties with high margins-of-error tend to be more rural, and a good number of these rural counties have as little as three census tracts compared to more urban counties that have nearly a hundred or more than two-hundred census tracts. Even counties marked with moderate confidence like Morgan, which is actually adjacent and northeast of Salt Lake county which has high confidence, have very little census tracts. When looking at the counties that have low confidence, it seems like the trend is that the confidence level has a positive relationship with income and population, and a negative relationship with margin-of-error as it rises. However, this trend seems to hold true for more densely populated counties, because Morgan county has a median income around 120,000 with moderate reliability and less than 12,000 residents, and Beaver county has a median income around 80,000 with low confidence and less than 8,000 residents. Income also has a strong relationship with race, so it can be inferred that Black and Hispanic communities may share similar relationship characteristics to the aforementioned statement, but this is in regards to more diverse, urban areas versus rural areas.\n\nBecause of these observations, the communities at greatest risk of algorithmic bias would be Black, Hispanic, rural, and low-income populations, and potentially other unmentioned races like Native Americans. Most of the US' diversity is a result from immigrants landing in coastal states and Black slaves who were very condensed in the South, and over the decades that diversity has moved to more inland states; Utah in particular had an overwhelming 98% white population in the entire state around the 1970s, and as of recently a little over five decades later, Utah is overall 90% white.\n\nIn addition, Utah's environment makes it particularly expensive to build in due to the desert and rocky environment that make construction difficult. It actually also makes it difficult to travel in as well, even with private vehicles due to the terrain. Much of Utah's topography is mountainous and desert, and rural communities do not have access to broadbandâ€”this means that the digital gap could be an obstacle to rural individuals, who receive the census surveys through mail, and who may have difficult mailing routes for the US Postal Service to reach. Most rural areas or developing towns, if they do possess internet cables, tend to be older and much slow infrastructure like copper, coaxial, or even satellite. These telecommunications technologies are very outdated compared to the current fiber optic standard. So census by mail is the best way to reach rural and Native reservations, and mail is not as timely to collect because of the physical and long-distance aspects that are required.\n\nTaking the liberty of observing the averages of margins-of-error less than 15% in section 4.2, it seems like the lower margin-of-error occurrences are within *even less* diverse tracts to others, with the white percent change being +15.23%, and then -0.98% and -12.50% percent changes for Black and Hispanic percents, respectively. From anecdotal knowledge, as a born-and-raised Utahn in Salt Lake county, the valley has the picturesque Wasatch mountains to the east and more flat and dusty mountain ranges to the far west as well as the Kennecott Copper Mine. The county is also split longitudinally by the main interstate highway I-15, and due to historical redlining and more frequent efforts to uplift communities near the Wasatch mountains, many of the wealthy and white residents live on the east side of I-15 and many of Salt Lake's diversity are clustered on the west side of I-15, namely the Black, Hispanic, and Asian communities.\n\nThe Department of Health and Human Services could work with the Department of Commerce, which oversees telecommunications, to develop a program that incentivizes or subsidizes telecommunications companies to build out fiber broadband networks with at least 250 to 300 Mbps. Because fiber is expensive to build out, companies can use older fiber cable technology to balance between the 500 Mbps to 1 GB commonly found in more urban regions. While rural areas receive the census by mail, the vast majority of ruralites own smartphones and do rely on their internet being reliable even if it's not very fast. So they won't have a lot of trouble navigating internet browsers, but filling out the census on mobile phone could be a potential hurdle, so local public facilities to them like libraries could facilitate in-person or virtual resources to fill out the census survey. The suggestion might result in a marginal change because most Americans use smartphones, but slow internet can often be a deterrent when filling out forms.\n\nThe margins-of-error that are higher in certain races in Utah could also be due to cultural differences, not a lot of immigrants, who make up the majority of BIPOC demographics, are able to read English well or they may be less likely to fill the census for a variety of reasons. In the 2020 ACS, only twelve languages were available to read the survey questions, and other languages outside the twelve require extra steps to receive translations; it could be worth pursuing creating a help center in public libraries as well for those who speak minority languages, but whether or not individuals come in for that public service is another thing entirely, so providing any online videos and glossaries in minority languages could be helpful, or allowing individuals to specify if they need a paper glossary with key translations mailed to them in their language.\n\n## 6.3 Specific Recommendations\n\n**Your Task:** Create a decision framework for algorithm implementation.\n\n```{r recommendations-data}\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\nsummary_table <- utah_reliability %>%\n  summarize(\n    \"County\" = utah_reliability[[\"NAME\"]],\n    \"Median Income\" = utah_reliability[[\"median_incE\"]],\n    \"MOE Percentage\" = utah_reliability[[\"MOE_percent\"]],\n    \"Reliability Category\" = utah_reliability[[\"reliability_cat\"]]\n  )\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\nsummary_table <- summary_table %>%\n  mutate(\n    \"Algorithm Recommendations\" = case_when(\n      `Reliability Category` == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n      `Reliability Category` == \"Moderate Confidence\" ~ \"Use with caution - monitor outcomes\",\n      `Reliability Category` == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n    )\n  )\n\n# Format as a professional table with kable()\nkable(\n  summary_table,\n  digit = 2,\n  caption = \"<b>UTAH COUNTIES: Median Income and Reliabillity for Algorithmic Decision-Making</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n\n```\n\n**Key Recommendations:**\n\n**Your Task:** Use your analysis results to provide specific guidance to the department.\n\n1. **Counties suitable for immediate algorithmic implementation:** Box Elder, Cache, Davis, Duchesne, Millard, Salt Lake, Tooele, Utah, Washington, and Weber counties have high confidence data, especially since all of these counties are either major urban regions in the state or they have a high population around 20,000 or more individuals. However, even if these counties are suitable for algorithmic implementation, it still needs to be stressed that automated decision-making should have flagging features built into them for potential review. The volume of data recorded in these counties are numerous and make any manual process in collecting and wrangling the data time-consuming, monotonous, and prone to human error. So balancing algorithmic implementation to do the heavy-lifting alongside human reviews when any flagging safeguards are breached could be crucial to maintain or further improve high confidence data.\n\n2. **Counties requiring additional oversight:** Carbon, Emery, Iron, Juab, Morgan, Sanpete, Sevier, Summit, Uintah, and Wasatch counties have moderate confidence data. Keeping an eye on how margins-of-error have changed over time in the census might be a worthwhile endeavor, if certain counties are gradually improving on their margins then oversight can ensure that their data reliability can transition to high confidence, and if certain counties have a history of their margins-of-error being stagnant, have higher variability year after year compared to other counties, or have been non a downward trend then it could be an option to introduce manual review in some parts of the data collection and cleaning process. Even sending out an additional survey might adjust the data confidence beneficially.\n\n3. **Counties needing alternative approaches:** Beaver, Daggett, Garfield, Grand, Kane, Piute, Rich, San Juan, and Wayne counties have low confidence data. These counties also happen to be in the more rural parts of Utah, which tend to have harsher desert environments and with rougher terrain when travelling, they also encompass all of the Native American reservations in Utah. These counties also have much smaller populations and population densities that could make them worth manually reviewing and sending out additional surveys to make sure people send them in. While USPS mail delivery procedures are largely the same, mailing to reservations have an additional unique challenge other than remoteness, which is that many residences don't have address names, so making sure that rural areas and reservations receive the census by sending more surveys could be part of a solution. The Department could also introduce a pilot program to provide P.O. boxes for reservations if Indigenous peoples in the region are open to the idea, although it'll be many long years before seeing whether or not it made substantial improvements to census data accuracy and lowering MOEs over time.\n\n## Questions for Further Investigation\n\n1. How would observations and interpretations change if other races were included, like Asians and Native Americans?\n\n2. Because the latest 5-year ACS for Utah had reported significant errors, how would that survey compare to previous surveys?\n\n3. How would this look spatially visualized? A deeper dive into neighborhoods with high MOE census tracts could be beneficial.\n\n4. What is the margin-of-error's relationship with population density and Utah's topography, in addition to median income?\n\n# Technical Notes\n\n**Data Sources:** \n- U.S. Census Bureau, American Community Survey 2018-2022 5-Year Estimates\n- Retrieved via tidycensus R package on 09/15/25.\n\n**Reproducibility:** \n- All analysis conducted in R version 4.5.1.\n- Census API key required for replication.\n- Complete code and documentation available at: https://github.com/MUSA-5080-Fall-2025/portfolio-setup-TessaVu\n\n**Methodology Notes:**\nBecause several values were zero, to get past the zero division hurdle the values were mutated to a smaller value like 0.01, which calculated extreme MOEs like 17,000.\n\n**Limitations:**\nThere were sample issues with tracts noting zero Black or Hispanic individuals, and dividing by zero created infinite values. This project selected Salt Lake, Morgan, and Piute counties, which have high, moderate, and low confidences, respectively. However, Morgan and Piute counties have very little census tracts at 4 and 5 compared to 200+ for Salt Lake. In addition, Utah was one of the 14 states in the recent 5-year census that over-counted its citizens by almost 3% with several individuals double-counted.\n\n---\n\n## Submission Checklist\n\nBefore submitting your portfolio link on Canvas:\n\n- [X] All code chunks run without errors\n- [X] All \"[Fill this in]\" prompts have been completed\n- [X] Tables are properly formatted and readable\n- [X] Executive summary addresses all four required components\n- [X] Portfolio navigation includes this assignment\n- [X] Census API key is properly set \n- [X] Document renders correctly to HTML\n\n**Remember:** Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/your_file_name.html`","srcMarkdownNoYaml":"\n\n# Assignment Overview\n\n## Scenario\n\nYou are a data analyst for the **Utah Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\n\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n## Learning Objectives\n\n- Apply dplyr functions to real census data for policy analysis\n- Evaluate data quality using margins of error \n- Connect technical analysis to algorithmic decision-making\n- Identify potential equity implications of data reliability issues\n- Create professional documentation for policy stakeholders\n\n## Submission Instructions\n\n**Submit by posting your updated portfolio link on Canvas.** Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/`\n\nMake sure to update your `_quarto.yml` navigation to include this assignment under an \"Assignments\" menu.\n\n# Part 1: Portfolio Integration\n\nCreate this assignment in your portfolio repository under an `assignments/assignment_1/` folder structure. Update your navigation menu to include:\n\n```\n- text: Assignments\n  menu:\n    - href: assignments/assignment_1/your_file_name.qmd\n      text: \"Assignment 1: Census Data Exploration\"\n```\nIf there is a special character like comma, you need use double quote mark so that the quarto can identify this as text\n\n# Setup\n\n```{r setup}\n# Load required packages (hint: you need tidycensus, tidyverse, and knitr)\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Set your Census API key\ncensus_api_key(\"3aaee31789e10b674a531e9f236c35d5394b19ed\")\n\n# Choose your state for analysis - assign it to a variable called my_state\nmy_state = \"Utah\"\n```\n\n**State Selection:** I've chosen **Utah** for this analysis because: It's my hometown and I grew up around Salt Lake valley area in different neighborhoods and would like to explore the data behind my memories and maybe how things have changed since I was last living there around 3 years ago.\n\n# Part 2: County-Level Resource Assessment\n\n## 2.1 Data Retrieval\n\n**Your Task:** Use `get_acs()` to retrieve county-level data for your chosen state.\n\n**Requirements:**\n- Geography: county level\n- Variables: median household income (B19013_001) and total population (B01003_001)  \n- Year: 2022\n- Survey: acs5\n- Output format: wide\n\n**Hint:** Remember to give your variables descriptive names using the `variables = c(name = \"code\")` syntax.\n\n```{r county-data}\n# Write your get_acs() code here\nutah_reliability <- get_acs(\n  geography = \"county\",\n  state = my_state,\n  # Median household income and total population.\n  variables = c(median_inc = \"B19013_001\", total_pop = \"B01003_001\"),\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\nutah_reliability <- mutate(utah_reliability, NAME = str_remove(NAME, \" County, Utah\"))\n\n# Display the first few rows\nglimpse(utah_reliability)\n```\n\n## 2.2 Data Quality Assessment\n\n**Your Task:** Calculate margin of error percentages and create reliability categories.\n\n**Requirements:**\n- Calculate MOE percentage: (margin of error / estimate) * 100\n- Create reliability categories:\n  - High Confidence: MOE < 5%\n  - Moderate Confidence: MOE 5-10%  \n  - Low Confidence: MOE > 10%\n- Create a flag for unreliable estimates (MOE > 10%)\n\n**Hint:** Use `mutate()` with `case_when()` for the categories.\n\n```{r income-reliability}\n# Calculate MOE percentage and reliability categories using mutate()\nutah_reliability <- mutate(utah_reliability, MOE_percent = (median_incM / median_incE) * 100) %>%\n                mutate(utah_reliability, reliability_cat =\n                         case_when(\n                           MOE_percent < 5 ~ \"High Confidence\",\n                           MOE_percent <= 10 ~ \"Moderate Confidence\",\n                           MOE_percent > 10 ~ \"Low Confidence\"\n                           )) %>%\n                mutate(utah_reliability, low_flag = reliability_cat == \"Low Confidence\")\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages\n\ncount_summary <- utah_reliability %>%\n  group_by(reliability_cat) %>%\n  summarize(frequency = n()) %>%\n  mutate(frequency = frequency) %>%\n  mutate(percent_counties = frequency / sum(frequency))\n\ncount_summary\n```\n\n## 2.3 High Uncertainty Counties\n\n**Your Task:** Identify the 5 counties with the highest MOE percentages.\n\n**Requirements:**\n- Sort by MOE percentage (highest first)\n- Select the top 5 counties\n- Display: county name, median income, margin of error, MOE percentage, reliability category\n- Format as a professional table using `kable()`\n\n**Hint:** Use `arrange()`, `slice()`, and `select()` functions.\n\n```{r high-uncertainty}\n# Create table of top 5 counties by MOE percentage\ntop_5 <- data.frame()\n\ntop_5 <- utah_reliability %>%\n  arrange(desc(MOE_percent)) %>%\n  slice(0:5) %>%\n  select(2:8)\n\n# Format as table with kable() - include appropriate column names and caption\nkable(\n  top_5,\n  col.names = c(\"County\", \"Median Income\", \"Median Income MOE\", \"Total Population\", \"Total Population MOE\", \"Percent MOE\", \"MOE Confidence\"),\n  digit = 2,\n  caption = \"<b>TOP 5 UTAH COUNTIES: HIGHEST MEDIAN INCOME MARGIN-OF-ERROR</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n  \n```\n\n**Data Quality Commentary:**\n\nThe top five counties with the highest MOEs are ruralâ€”Piute, Wayne, Daggett, and Kane counties lack a major interstate highway in a state with cities that rely on car-transport within urban areas as well as within the vast swaths of undeveloped desert land. Beaver county at fifth does have the I-15 freeway. Another factor is the environmental topography that could influence towns' infrastructure expansion as well as travel, all five counties' are mountainous regions for the majority of their landscape, making it difficult and expensive to develop.\n\n# Part 3: Neighborhood-Level Analysis\n\n## 3.1 Focus Area Selection\n\n**Your Task:** Select 2-3 counties from your reliability analysis for detailed tract-level study.\n\n**Strategy:** Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n```{r select-counties}\n# Use filter() to select 2-3 counties from your utah_reliability data\n# Store the selected counties in a variable called selected_counties\nselected_counties <- utah_reliability %>%\n  filter(NAME == \"Salt Lake\" | NAME == \"Morgan\" | NAME == \"Piute\") %>%\n  arrange(MOE_percent)\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\nkable(\n  selected_counties[c(\"GEOID\", \"NAME\", \"median_incE\", \"MOE_percent\", \"reliability_cat\")],\n  col.names = c(\"GEOID\", \"County\", \"Median Income\", \"MOE Percentage\", \"MOE Confidence\"),\n  digit = 2,\n  caption = \"<b>SELECTED UTAH COUNTIES</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n```\n\n**Comment on the output:** This table output shows Salt Lake, Morgan, and Piute counties, which have high, moderate, and low confidence, respectively. Salt Lake has a 1.17% MOE percentage and Morgan has a 7.78% MOE percentage, Piute has a significant jump from Morgan by 29.33% units at 37.11%. Salt Lake and Morgan are counties that are actually adjacent to one another, whereas Piute is in central, rural Utah.\n\n## 3.2 Tract-Level Demographics\n\n**Your Task:** Get demographic data for census tracts in your selected counties.\n\n**Requirements:**\n- Geography: tract level\n- Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001)\n- Use the same state and year as before\n- Output format: wide\n- **Challenge:** You'll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n```{r tract-demographics}\n# Define your race/ethnicity variables with descriptive names\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\ntract_level <- get_acs(\n  geography = \"tract\",\n  state = my_state,\n  # Median household income and total population.\n  variables = c(white = \"B03002_003\", black = \"B03002_004\", hispanic = \"B03002_012\", total = \"B03002_001\"),\n  year = 2022,\n  survey = \"acs5\",\n  output = \"wide\"\n) %>%\n  filter(str_detect(GEOID, \"^49035\") | str_detect(GEOID, \"^49029\") | str_detect(GEOID, \"^49031\"))\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\ntract_level <- tract_level %>%\n  mutate(\n    \"White Percentage\" = (whiteE / totalE) * 100,\n    \"Black Percentage\" = (blackE / totalE) * 100,\n    \"Hispanic Percentage\" = (hispanicE / totalE) * 100\n  )\n\n# Add readable tract and county name columns using str_extract() or similar\ntract_level <- tract_level %>%\n  separate(\n    col = NAME,\n    into = c(\"TRACT\", \"COUNTY\", \"STATE\"),\n    sep = \";\"\n  )\n\ntract_level\n  \n```\n\n## 3.3 Demographic Analysis\n\n**Your Task:** Analyze the demographic patterns in your selected areas.\n\n```{r demographic-analysis}\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\ntract_level <- tract_level %>%\n  arrange(desc(`Hispanic Percentage`))\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\ntract_level_summary <- tract_level %>%\n  group_by(COUNTY) %>%\n  summarize(\"Number of Tracts\" = n(),\n            \"White Average Percent\" = mean(`White Percentage`, na.rm = TRUE),\n            \"Black Average Percent\" = mean(`Black Percentage`, na.rm = TRUE),\n            \"Hispanic Average Percent\" = mean(`Hispanic Percentage`, na.rm = TRUE)\n            )\n\n# Create a nicely formatted table of your results using kable()\nkable(\n  tract_level_summary,\n  caption = \"<b>SELECTED UTAH COUNTIES: Average Racial Percents</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n```\n\n# Part 4: Comprehensive Data Quality Evaluation\n\n## 4.1 MOE Analysis for Demographic Variables\n\n**Your Task:** Examine margins of error for demographic variables to see if some communities have less reliable data.\n\n**Requirements:**\n- Calculate MOE percentages for each demographic variable\n- Flag tracts where any demographic variable has MOE > 15%\n- Create summary statistics\n\n```{r demographic-moe}\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\noptions(scipen = 999)\n\n# Avoid Inf values by changing 0 values to 0.01.\nMOE_percentages <- tract_level %>%\n  mutate(across(c(whiteM, whiteE, blackM, blackE, hispanicM, hispanicE),\n                ~ifelse(. == 0, 0.1, .)))\n\nMOE_percentages <- MOE_percentages %>%\n  mutate(\n    \"White MOE\" = (whiteM / whiteE) * 100,\n    \"Black MOE\" = (blackM / blackE) * 100,\n    \"Hispanic MOE\" = (hispanicM / hispanicE) * 100\n  )\n\n# Use logical operators (| for OR) in an ifelse() statement\nMOE_percentages <- MOE_percentages %>%\n  mutate(MOE_percentages,\n         \"MOE Flag\" = if_else(\n           `White MOE` > 15 | `Black MOE` > 15 | `Hispanic MOE` > 15, TRUE, FALSE\n         )\n  )\n\n# Create summary statistics showing how many tracts have data quality issues\ndata_quality_summary <- MOE_percentages %>%\n  group_by(COUNTY) %>%\n  summarize(\n    \"Number of Tracts\" = n(),\n    \"Data Quality Issues\" = sum(`MOE Flag`, na.rm = TRUE)\n    )\n\ndata_quality_summary\n\n```\n\n## 4.2 Pattern Analysis\n\n**Your Task:** Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n```{r pattern-analysis}\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n# Use group_by() and summarize() to create this comparison\n\nflagged_MOE <- MOE_percentages %>%\n  group_by(`MOE Flag`) %>%\n  summarize(\n    \"Avg White\" = mean(whiteE, na.rm = TRUE), \"Avg % White\" = mean(`White Percentage`, na.rm = TRUE),\n    \"Avg Black\" = mean(blackE, na.rm = TRUE), \"Avg % Black\" = mean(`Black Percentage`, na.rm = TRUE),\n    \"Avg Hispanic\" = mean(hispanicE, na.rm = TRUE), \"Avg % Hispanic\" = mean(`Hispanic Percentage`, na.rm = TRUE)\n    )\n\n# Create a professional table showing the patterns\nkable(\n  flagged_MOE,\n  digit = 2,\n  caption = \"<b>SALT LAKE, MORGAN, AND PIUTE COUNTIES: Average Population and Percents by Race</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n\n```\n\n```{r}\n# Check minimums.\nmin(MOE_percentages[[\"White MOE\"]])\nmin(MOE_percentages[[\"Black MOE\"]])\nmin(MOE_percentages[[\"Hispanic MOE\"]])\n\n# Flag tracts with MOES below 15%.\nlow_MOE <- MOE_percentages %>%\n  mutate(MOE_percentages,\n         \"Low MOE\" = if_else(\n           `White MOE` < 15 | `Black MOE` < 15 | `Hispanic MOE` < 15, TRUE, FALSE\n         )\n  )\n\n# Group low MOEs.\nlow_MOE_summary <- low_MOE %>%\n  group_by(`Low MOE`) %>%\n  summarize(\n    \"Avg White\" = mean(whiteE, na.rm = TRUE), \"Avg % White\" = mean(`White Percentage`, na.rm = TRUE),\n    \"Avg Black\" = mean(blackE, na.rm = TRUE), \"Avg % Black\" = mean(`Black Percentage`, na.rm = TRUE),\n    \"Avg Hispanic\" = mean(hispanicE, na.rm = TRUE), \"Avg % Hispanic\" = mean(`Hispanic Percentage`, na.rm = TRUE)\n    )\n  \nlow_MOE_summary\n\n```\n\n**Pattern Analysis:** All of the census tracts in Salt Lake, Morgan, and Piute counties had MOEs above 15%, and judging off of that it seems like the census had significant MOEs for the three races. However, when looking at the minimum MOE percentages, the white population's range starts at 6.31%, and Hispanic at 17.60% and Black at 54.39%, which are both substantial jumps from the white communities. Possible explanations might be due to redlining, and from anecdotal knowledge, the diversity in Salt Lake county tends to be clustered on the west side and periphery with higher Black, Hispanic, and Asian populations. Another explanation could be that the other counties are smaller and have a much larger white population.\n\n# Part 5: Policy Recommendations\n\n## 5.1 Analysis Integration and Professional Summary\n\n**Your Task:** Write an executive summary that integrates findings from all four analyses.\n\n**Executive Summary Requirements:**\n1. **Overall Pattern Identification**: What are the systematic patterns across all your analyses?\n2. **Equity Assessment**: Which communities face the greatest risk of algorithmic bias based on your findings?\n3. **Root Cause Analysis**: What underlying factors drive both data quality issues and bias risk?\n4. **Strategic Recommendations**: What should the Department implement to address these systematic issues?\n\n**Executive Summary:**\n\nLooking at the data without any geographic or chart visualization, it seems like many of the counties with high margins-of-error tend to be more rural, and a good number of these rural counties have as little as three census tracts compared to more urban counties that have nearly a hundred or more than two-hundred census tracts. Even counties marked with moderate confidence like Morgan, which is actually adjacent and northeast of Salt Lake county which has high confidence, have very little census tracts. When looking at the counties that have low confidence, it seems like the trend is that the confidence level has a positive relationship with income and population, and a negative relationship with margin-of-error as it rises. However, this trend seems to hold true for more densely populated counties, because Morgan county has a median income around 120,000 with moderate reliability and less than 12,000 residents, and Beaver county has a median income around 80,000 with low confidence and less than 8,000 residents. Income also has a strong relationship with race, so it can be inferred that Black and Hispanic communities may share similar relationship characteristics to the aforementioned statement, but this is in regards to more diverse, urban areas versus rural areas.\n\nBecause of these observations, the communities at greatest risk of algorithmic bias would be Black, Hispanic, rural, and low-income populations, and potentially other unmentioned races like Native Americans. Most of the US' diversity is a result from immigrants landing in coastal states and Black slaves who were very condensed in the South, and over the decades that diversity has moved to more inland states; Utah in particular had an overwhelming 98% white population in the entire state around the 1970s, and as of recently a little over five decades later, Utah is overall 90% white.\n\nIn addition, Utah's environment makes it particularly expensive to build in due to the desert and rocky environment that make construction difficult. It actually also makes it difficult to travel in as well, even with private vehicles due to the terrain. Much of Utah's topography is mountainous and desert, and rural communities do not have access to broadbandâ€”this means that the digital gap could be an obstacle to rural individuals, who receive the census surveys through mail, and who may have difficult mailing routes for the US Postal Service to reach. Most rural areas or developing towns, if they do possess internet cables, tend to be older and much slow infrastructure like copper, coaxial, or even satellite. These telecommunications technologies are very outdated compared to the current fiber optic standard. So census by mail is the best way to reach rural and Native reservations, and mail is not as timely to collect because of the physical and long-distance aspects that are required.\n\nTaking the liberty of observing the averages of margins-of-error less than 15% in section 4.2, it seems like the lower margin-of-error occurrences are within *even less* diverse tracts to others, with the white percent change being +15.23%, and then -0.98% and -12.50% percent changes for Black and Hispanic percents, respectively. From anecdotal knowledge, as a born-and-raised Utahn in Salt Lake county, the valley has the picturesque Wasatch mountains to the east and more flat and dusty mountain ranges to the far west as well as the Kennecott Copper Mine. The county is also split longitudinally by the main interstate highway I-15, and due to historical redlining and more frequent efforts to uplift communities near the Wasatch mountains, many of the wealthy and white residents live on the east side of I-15 and many of Salt Lake's diversity are clustered on the west side of I-15, namely the Black, Hispanic, and Asian communities.\n\nThe Department of Health and Human Services could work with the Department of Commerce, which oversees telecommunications, to develop a program that incentivizes or subsidizes telecommunications companies to build out fiber broadband networks with at least 250 to 300 Mbps. Because fiber is expensive to build out, companies can use older fiber cable technology to balance between the 500 Mbps to 1 GB commonly found in more urban regions. While rural areas receive the census by mail, the vast majority of ruralites own smartphones and do rely on their internet being reliable even if it's not very fast. So they won't have a lot of trouble navigating internet browsers, but filling out the census on mobile phone could be a potential hurdle, so local public facilities to them like libraries could facilitate in-person or virtual resources to fill out the census survey. The suggestion might result in a marginal change because most Americans use smartphones, but slow internet can often be a deterrent when filling out forms.\n\nThe margins-of-error that are higher in certain races in Utah could also be due to cultural differences, not a lot of immigrants, who make up the majority of BIPOC demographics, are able to read English well or they may be less likely to fill the census for a variety of reasons. In the 2020 ACS, only twelve languages were available to read the survey questions, and other languages outside the twelve require extra steps to receive translations; it could be worth pursuing creating a help center in public libraries as well for those who speak minority languages, but whether or not individuals come in for that public service is another thing entirely, so providing any online videos and glossaries in minority languages could be helpful, or allowing individuals to specify if they need a paper glossary with key translations mailed to them in their language.\n\n## 6.3 Specific Recommendations\n\n**Your Task:** Create a decision framework for algorithm implementation.\n\n```{r recommendations-data}\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\nsummary_table <- utah_reliability %>%\n  summarize(\n    \"County\" = utah_reliability[[\"NAME\"]],\n    \"Median Income\" = utah_reliability[[\"median_incE\"]],\n    \"MOE Percentage\" = utah_reliability[[\"MOE_percent\"]],\n    \"Reliability Category\" = utah_reliability[[\"reliability_cat\"]]\n  )\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\nsummary_table <- summary_table %>%\n  mutate(\n    \"Algorithm Recommendations\" = case_when(\n      `Reliability Category` == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n      `Reliability Category` == \"Moderate Confidence\" ~ \"Use with caution - monitor outcomes\",\n      `Reliability Category` == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n    )\n  )\n\n# Format as a professional table with kable()\nkable(\n  summary_table,\n  digit = 2,\n  caption = \"<b>UTAH COUNTIES: Median Income and Reliabillity for Algorithmic Decision-Making</b>\"\n) %>%\n  kable_styling(latex_options = \"striped\") %>%\n  column_spec(1, bold = TRUE) %>%\n  row_spec(0, color = \"white\", background = \"black\")\n\n```\n\n**Key Recommendations:**\n\n**Your Task:** Use your analysis results to provide specific guidance to the department.\n\n1. **Counties suitable for immediate algorithmic implementation:** Box Elder, Cache, Davis, Duchesne, Millard, Salt Lake, Tooele, Utah, Washington, and Weber counties have high confidence data, especially since all of these counties are either major urban regions in the state or they have a high population around 20,000 or more individuals. However, even if these counties are suitable for algorithmic implementation, it still needs to be stressed that automated decision-making should have flagging features built into them for potential review. The volume of data recorded in these counties are numerous and make any manual process in collecting and wrangling the data time-consuming, monotonous, and prone to human error. So balancing algorithmic implementation to do the heavy-lifting alongside human reviews when any flagging safeguards are breached could be crucial to maintain or further improve high confidence data.\n\n2. **Counties requiring additional oversight:** Carbon, Emery, Iron, Juab, Morgan, Sanpete, Sevier, Summit, Uintah, and Wasatch counties have moderate confidence data. Keeping an eye on how margins-of-error have changed over time in the census might be a worthwhile endeavor, if certain counties are gradually improving on their margins then oversight can ensure that their data reliability can transition to high confidence, and if certain counties have a history of their margins-of-error being stagnant, have higher variability year after year compared to other counties, or have been non a downward trend then it could be an option to introduce manual review in some parts of the data collection and cleaning process. Even sending out an additional survey might adjust the data confidence beneficially.\n\n3. **Counties needing alternative approaches:** Beaver, Daggett, Garfield, Grand, Kane, Piute, Rich, San Juan, and Wayne counties have low confidence data. These counties also happen to be in the more rural parts of Utah, which tend to have harsher desert environments and with rougher terrain when travelling, they also encompass all of the Native American reservations in Utah. These counties also have much smaller populations and population densities that could make them worth manually reviewing and sending out additional surveys to make sure people send them in. While USPS mail delivery procedures are largely the same, mailing to reservations have an additional unique challenge other than remoteness, which is that many residences don't have address names, so making sure that rural areas and reservations receive the census by sending more surveys could be part of a solution. The Department could also introduce a pilot program to provide P.O. boxes for reservations if Indigenous peoples in the region are open to the idea, although it'll be many long years before seeing whether or not it made substantial improvements to census data accuracy and lowering MOEs over time.\n\n## Questions for Further Investigation\n\n1. How would observations and interpretations change if other races were included, like Asians and Native Americans?\n\n2. Because the latest 5-year ACS for Utah had reported significant errors, how would that survey compare to previous surveys?\n\n3. How would this look spatially visualized? A deeper dive into neighborhoods with high MOE census tracts could be beneficial.\n\n4. What is the margin-of-error's relationship with population density and Utah's topography, in addition to median income?\n\n# Technical Notes\n\n**Data Sources:** \n- U.S. Census Bureau, American Community Survey 2018-2022 5-Year Estimates\n- Retrieved via tidycensus R package on 09/15/25.\n\n**Reproducibility:** \n- All analysis conducted in R version 4.5.1.\n- Census API key required for replication.\n- Complete code and documentation available at: https://github.com/MUSA-5080-Fall-2025/portfolio-setup-TessaVu\n\n**Methodology Notes:**\nBecause several values were zero, to get past the zero division hurdle the values were mutated to a smaller value like 0.01, which calculated extreme MOEs like 17,000.\n\n**Limitations:**\nThere were sample issues with tracts noting zero Black or Hispanic individuals, and dividing by zero created infinite values. This project selected Salt Lake, Morgan, and Piute counties, which have high, moderate, and low confidences, respectively. However, Morgan and Piute counties have very little census tracts at 4 and 5 compared to 200+ for Salt Lake. In addition, Utah was one of the 14 states in the recent 5-year census that over-counted its citizens by almost 3% with several individuals double-counted.\n\n---\n\n## Submission Checklist\n\nBefore submitting your portfolio link on Canvas:\n\n- [X] All code chunks run without errors\n- [X] All \"[Fill this in]\" prompts have been completed\n- [X] Tables are properly formatted and readable\n- [X] Executive summary addresses all four required components\n- [X] Portfolio navigation includes this assignment\n- [X] Census API key is properly set \n- [X] Document renders correctly to HTML\n\n**Remember:** Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at `your-portfolio-url/assignments/assignment_1/your_file_name.html`"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"lab-1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"lux","title":"Assignment 1: Census Data Quality for Policy Decisions","subtitle":"Evaluating Data Reliability for Algorithmic Decision-Making","author":"Tessa Vu","date":"2025-09-08","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}