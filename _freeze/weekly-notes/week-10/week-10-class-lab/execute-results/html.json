{
  "hash": "f1740d6bc8c802ab21384a894e77ca38",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: LOGISTIC REGRESSION WITH EQUITY ANALYSIS\nsubtitle: WEEK 10 IN-CLASS LAB\ndate: 2025-11-10\nauthor:\n  - name: Tess Vu\n    email:\n      - tessavu@proton.me\n      - tessavu@upenn.edu\n    corresponding: TRUE\naffiliation:\n  - name: University of Pennsylvania\n    department: Urban Spatial Analytics (MUSA)\n    city: Philadelphia\n    state: PA\n    url: https://www.design.upenn.edu/urban-spatial-analytics\nformat:\n  html:\n    code-fold: show\n    toc: true\n    toc-location: left\n    toc-expand: true\n    smooth-scroll: true\n    embed-resources: true\n    title-block-style: default\nexecute:\n  warning: false\n  message: false\n---\n\n# Logistic Regression with Equity Analysis\n\n## Week 10: MUSA 5080 Public Policy Analytics\n\nThis script demonstrates how to:\n\n1. Build a logistic regression model for binary classification\n\n2. Evaluate model performance using multiple metrics\n\n3. Analyze disparate impact across demographic groups\n\n4. Test different decision thresholds\n\n5. Make evidence-based policy recommendations\n\n# SETUP\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\n\nlibrary(tidyverse) # For data manipulation and visualization\nlibrary(caret) # For model training and confusion matrices library\nlibrary(pROC) # For ROC curves and AUC\n\n# Set random seed for reproducibility\n\nset.seed(2025)\n\n# Configure visualization theme\ntheme_set(theme_minimal())\n```\n:::\n\n\n# PART 1: DATA LOADING AND EXPLORATION\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Load Georgia Department of Corrections recidivism data\n\n# Source: National Institute of Justice Recidivism Challenge\n\nrecidivism_data <- read_csv(\"data/NIJ_s_Recidivism_Challenge_Full_Dataset_20240407.csv\") # Examine data structure glimpse(recidivism_data)\n\n# Check outcome variable distribution\n\ntable(recidivism_data$Recidivism_Within_3years, useNA = \"ifany\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFALSE  TRUE \n10931 14904 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate overall recidivism rate\n\nmean(recidivism_data$Recidivism_Within_3years, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5768918\n```\n\n\n:::\n\n```{.r .cell-code}\n# Examine recidivism rates by race\n\nrecidivism_data %>%\n  filter(!is.na(Race), !is.na(Recidivism_Within_3years)) %>%\n  group_by(Race) %>%\n  summarise(n = n(),\n            recidivism_rate = mean(Recidivism_Within_3years),\n            avg_age = mean(Age_at_Release, na.rm = TRUE),\n            avg_prior_felonies = mean(Prior_Arrest_Episodes_Felony, na.rm = TRUE)\n            ) %>%\n  arrange(desc(recidivism_rate))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  Race      n recidivism_rate avg_age avg_prior_felonies\n  <chr> <int>           <dbl>   <dbl>              <dbl>\n1 BLACK 14847           0.587      NA                 NA\n2 WHITE 10988           0.563      NA                 NA\n```\n\n\n:::\n:::\n\n\nCRITICAL QUESTION: Why do base rates differ across groups?\n\n- Consider both individual factors and systemic factors (differential policing, economic opportunities, program access, etc.)\n\n# PART 2: DATA PREPARATION\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean and prepare data for modeling\n\nmodel_data <- recidivism_data %>% # Create binary outcome variable (must be numeric for glm)\n  mutate(recidivism = as.integer(Recidivism_Within_3years == TRUE)) %>% # Select relevant features\n  select(recidivism, # Outcome\n         Age_at_Release, # Demographics\n         Gender, Race, Gang_Affiliated, # Risk factors\n         Dependents, Prior_Arrest_Episodes_Felony, # Criminal history\n         Prior_Arrest_Episodes_Violent, Prior_Conviction_Episodes_Prop, Condition_MH_SA, # Mental health / substance abuse\n         Supervision_Risk_Score_First, # Official risk score\n         Percent_Days_Employed, # Economic factors\n         Education_Level # Education\n         ) %>%\n  # Remove missing values (in practice, consider imputation)\n  na.omit()\n\n# Check final sample characteristics\n\ncat(\"Final sample size:\", nrow(model_data), \"individualsn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFinal sample size: 21837 individualsn\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Recidivism rate:\", round(mean(model_data$recidivism), 3), \"nn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRecidivism rate: 0.604 nn\n```\n\n\n:::\n\n```{.r .cell-code}\n# Sample size by race\n\nmodel_data %>%\n  count(Race) %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  Race      n\n  <chr> <int>\n1 BLACK 13220\n2 WHITE  8617\n```\n\n\n:::\n:::\n\n\n# PART 3: TRAIN-TEST SPLIT\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create stratified train-test split (maintains outcome distribution)\n\ntrainIndex <- createDataPartition(y = model_data$recidivism, p = 0.70, # 70% training, 30% testing\n                                  list = FALSE )\n\ntrain_data <- model_data[trainIndex, ]\ntest_data <- model_data[-trainIndex, ]\n\n# Verify split preserves outcome distribution\n\ncat(\"Training set:n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining set:n\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" N =\", nrow(train_data), \"n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n N = 15286 n\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" Recidivism rate =\", round(mean(train_data$recidivism), 3), \"nn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Recidivism rate = 0.606 nn\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Test set:n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest set:n\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" N =\", nrow(test_data), \"n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n N = 6551 n\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" Recidivism rate =\", round(mean(test_data$recidivism), 3), \"nn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Recidivism rate = 0.599 nn\n```\n\n\n:::\n:::\n\n\n# PART 4: MODEL TRAINING\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit logistic regression model\n\n# Note: We're excluding Race from predictors to avoid direct discrimination,\n\n# but this doesn't eliminate bias (proxy variables may exist)\n\nlogit_model <- glm(recidivism ~\n                     Age_at_Release + Dependents + Gang_Affiliated + Prior_Arrest_Episodes_Felony +\n                     Prior_Arrest_Episodes_Violent + Prior_Conviction_Episodes_Prop + Percent_Days_Employed +\n                     Supervision_Risk_Score_First, data = train_data, family = \"binomial\") # Specifies logistic regression\n\n# View model summary\n\nsummary(logit_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = recidivism ~ Age_at_Release + Dependents + Gang_Affiliated + \n    Prior_Arrest_Episodes_Felony + Prior_Arrest_Episodes_Violent + \n    Prior_Conviction_Episodes_Prop + Percent_Days_Employed + \n    Supervision_Risk_Score_First, family = \"binomial\", data = train_data)\n\nCoefficients:\n                                         Estimate Std. Error z value Pr(>|z|)\n(Intercept)                              1.536623   0.205913   7.462 8.49e-14\nAge_at_Release23-27                     -0.306180   0.078571  -3.897 9.75e-05\nAge_at_Release28-32                     -0.626801   0.082161  -7.629 2.37e-14\nAge_at_Release33-37                     -0.884262   0.087578 -10.097  < 2e-16\nAge_at_Release38-42                     -1.097585   0.095083 -11.543  < 2e-16\nAge_at_Release43-47                     -1.328051   0.099313 -13.372  < 2e-16\nAge_at_Release48 or older               -1.774217   0.098409 -18.029  < 2e-16\nDependents1                              0.112010   0.051801   2.162 0.030593\nDependents2                              0.118375   0.055002   2.152 0.031382\nDependents3 or more                     -0.022584   0.047740  -0.473 0.636171\nGang_AffiliatedTRUE                      0.760899   0.057000  13.349  < 2e-16\nPrior_Arrest_Episodes_Felony1           -1.262064   0.197966  -6.375 1.83e-10\nPrior_Arrest_Episodes_Felony10 or more   0.484253   0.197974   2.446 0.014444\nPrior_Arrest_Episodes_Felony2           -0.723727   0.196190  -3.689 0.000225\nPrior_Arrest_Episodes_Felony3           -0.513387   0.196169  -2.617 0.008869\nPrior_Arrest_Episodes_Felony4           -0.320167   0.196595  -1.629 0.103406\nPrior_Arrest_Episodes_Felony5           -0.201793   0.197509  -1.022 0.306928\nPrior_Arrest_Episodes_Felony6           -0.061271   0.199735  -0.307 0.759025\nPrior_Arrest_Episodes_Felony7           -0.180865   0.201464  -0.898 0.369318\nPrior_Arrest_Episodes_Felony8            0.046340   0.205038   0.226 0.821197\nPrior_Arrest_Episodes_Felony9            0.137792   0.209034   0.659 0.509777\nPrior_Arrest_Episodes_Violent1           0.070370   0.044557   1.579 0.114264\nPrior_Arrest_Episodes_Violent2           0.109302   0.056685   1.928 0.053827\nPrior_Arrest_Episodes_Violent3 or more   0.167071   0.058030   2.879 0.003989\nPrior_Conviction_Episodes_Prop1          0.144881   0.047901   3.025 0.002490\nPrior_Conviction_Episodes_Prop2          0.230322   0.061184   3.764 0.000167\nPrior_Conviction_Episodes_Prop3 or more  0.431137   0.061050   7.062 1.64e-12\nPercent_Days_Employed                   -1.124559   0.043608 -25.788  < 2e-16\nSupervision_Risk_Score_First             0.022286   0.009194   2.424 0.015352\n                                           \n(Intercept)                             ***\nAge_at_Release23-27                     ***\nAge_at_Release28-32                     ***\nAge_at_Release33-37                     ***\nAge_at_Release38-42                     ***\nAge_at_Release43-47                     ***\nAge_at_Release48 or older               ***\nDependents1                             *  \nDependents2                             *  \nDependents3 or more                        \nGang_AffiliatedTRUE                     ***\nPrior_Arrest_Episodes_Felony1           ***\nPrior_Arrest_Episodes_Felony10 or more  *  \nPrior_Arrest_Episodes_Felony2           ***\nPrior_Arrest_Episodes_Felony3           ** \nPrior_Arrest_Episodes_Felony4              \nPrior_Arrest_Episodes_Felony5              \nPrior_Arrest_Episodes_Felony6              \nPrior_Arrest_Episodes_Felony7              \nPrior_Arrest_Episodes_Felony8              \nPrior_Arrest_Episodes_Felony9              \nPrior_Arrest_Episodes_Violent1             \nPrior_Arrest_Episodes_Violent2          .  \nPrior_Arrest_Episodes_Violent3 or more  ** \nPrior_Conviction_Episodes_Prop1         ** \nPrior_Conviction_Episodes_Prop2         ***\nPrior_Conviction_Episodes_Prop3 or more ***\nPercent_Days_Employed                   ***\nSupervision_Risk_Score_First            *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 20500  on 15285  degrees of freedom\nResidual deviance: 17780  on 15257  degrees of freedom\nAIC: 17838\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\n# Interpret coefficients as odds ratios\n\nexp(coef(logit_model))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            (Intercept)                     Age_at_Release23-27 \n                              4.6488629                               0.7362542 \n                    Age_at_Release28-32                     Age_at_Release33-37 \n                              0.5342983                               0.4130187 \n                    Age_at_Release38-42                     Age_at_Release43-47 \n                              0.3336758                               0.2649933 \n              Age_at_Release48 or older                             Dependents1 \n                              0.1696161                               1.1185242 \n                            Dependents2                     Dependents3 or more \n                              1.1256661                               0.9776691 \n                    Gang_AffiliatedTRUE           Prior_Arrest_Episodes_Felony1 \n                              2.1401994                               0.2830692 \n Prior_Arrest_Episodes_Felony10 or more           Prior_Arrest_Episodes_Felony2 \n                              1.6229618                               0.4849416 \n          Prior_Arrest_Episodes_Felony3           Prior_Arrest_Episodes_Felony4 \n                              0.5984653                               0.7260279 \n          Prior_Arrest_Episodes_Felony5           Prior_Arrest_Episodes_Felony6 \n                              0.8172644                               0.9405683 \n          Prior_Arrest_Episodes_Felony7           Prior_Arrest_Episodes_Felony8 \n                              0.8345479                               1.0474303 \n          Prior_Arrest_Episodes_Felony9          Prior_Arrest_Episodes_Violent1 \n                              1.1477367                               1.0729050 \n         Prior_Arrest_Episodes_Violent2  Prior_Arrest_Episodes_Violent3 or more \n                              1.1154991                               1.1818388 \n        Prior_Conviction_Episodes_Prop1         Prior_Conviction_Episodes_Prop2 \n                              1.1559020                               1.2590059 \nPrior_Conviction_Episodes_Prop3 or more                   Percent_Days_Employed \n                              1.5390061                               0.3247958 \n           Supervision_Risk_Score_First \n                              1.0225361 \n```\n\n\n:::\n\n```{.r .cell-code}\n# INTERPRETATION NOTE:\n\n# Coefficients show log-odds relationship\n\n# Odds ratios > 1 indicate increased risk\n\n# Odds ratios < 1 indicate decreased risk\n```\n:::\n\n\n# PART 5: GENERATING PREDICTIONS\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate predicted probabilities on test set\n\ntest_data <- test_data %>%\n  mutate(predicted_prob = predict(logit_model, newdata = test_data, type = \"response\"))\n\n# Examine distribution of predicted probabilities\n\nsummary(test_data$predicted_prob)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.07046 0.45871 0.63226 0.60528 0.76880 0.96374 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualize predicted probabilities by actual outcome\n\nggplot(test_data,\n       aes(x = predicted_prob,\n           fill = as.factor(recidivism))\n       ) +\n  geom_histogram(bins = 50, alpha = 0.7, position = \"identity\"\n                 ) +\n  scale_fill_manual(values = c(\"steelblue\", \"coral\"),\n                    labels = c(\"No Recidivism\", \"Recidivism\")\n                    ) +\n  labs(title = \"Distribution of Predicted Probabilities\",\n       x = \"Predicted Probability of Recidivism\",\n       y = \"Count\",\n       fill = \"Actual Outcome\")\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# PART 6: MODEL EVALUATION - OVERALL PERFORMANCE\n\n## 6.1: Confusion Matrix at Default Threshold (0.5)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_data <- test_data %>%\n  mutate(predicted_class_50 = ifelse(predicted_prob > 0.5, 1, 0))\n\n# Create confusion matrix\n\ncm_50 <- confusionMatrix(as.factor(test_data$predicted_class_50),\n  as.factor(test_data$recidivism), positive = \"1\") # \"1\" is the positive class (recidivism)\n\nprint(cm_50)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1294  719\n         1 1334 3204\n                                          \n               Accuracy : 0.6866          \n                 95% CI : (0.6752, 0.6978)\n    No Information Rate : 0.5988          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.3215          \n                                          \n Mcnemar's Test P-Value : < 2.2e-16       \n                                          \n            Sensitivity : 0.8167          \n            Specificity : 0.4924          \n         Pos Pred Value : 0.7060          \n         Neg Pred Value : 0.6428          \n             Prevalence : 0.5988          \n         Detection Rate : 0.4891          \n   Detection Prevalence : 0.6927          \n      Balanced Accuracy : 0.6546          \n                                          \n       'Positive' Class : 1               \n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\n# Extract key metrics\n\ncat(\"nKey Metrics at Threshold = 0.5:n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nnKey Metrics at Threshold = 0.5:n\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Sensitivity (Recall):\", round(cm_50$byClass[\"Sensitivity\"], 3),\n    \"- Proportion of actual recidivists correctly identifiedn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSensitivity (Recall): 0.817 - Proportion of actual recidivists correctly identifiedn\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Specificity:\", round(cm_50$byClass[\"Specificity\"], 3), \"- Proportion of non-recidivists correctly identifiedn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSpecificity: 0.492 - Proportion of non-recidivists correctly identifiedn\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Precision (PPV):\", round(cm_50$byClass[\"Precision\"], 3),\n    \"- Proportion of predicted recidivists who actually recidivatedn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPrecision (PPV): 0.706 - Proportion of predicted recidivists who actually recidivatedn\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Accuracy:\", round(cm_50$overall[\"Accuracy\"], 3), \"nn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAccuracy: 0.687 nn\n```\n\n\n:::\n:::\n\n\n## 6.2: ROC Curve and AUC\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate ROC curve\n\nroc_obj <- roc(response = test_data$recidivism,\n  predictor = test_data$predicted_prob )\n\n# Plot ROC curve\n\nggroc(roc_obj,\n      color = \"steelblue\",\n      size = 1.5\n      ) +\n  geom_abline(slope = 1,\n              intercept = 1,\n              linetype = \"dashed\",\n              color = \"gray50\"\n              ) +\n  labs(title = \"ROC Curve: Recidivism Prediction Model\",\n       subtitle = paste0(\"AUC = \", round(auc(roc_obj), 3)),\n       x = \"1 - Specificity (False Positive Rate)\",\n       y = \"Sensitivity (True Positive Rate)\"\n       ) +\n  annotate(\"text\",\n           x = 0.5,\n           y = 0.3,\n           label = \"Random Classifiern(AUC = 0.5)\",\n           color = \"gray50\",\n           size = 3\n           ) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Print AUC\n\ncat(\"Area Under the Curve (AUC):\", round(auc(roc_obj), 3), \"n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea Under the Curve (AUC): 0.732 n\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Interpretation: AUC of\", round(auc(roc_obj), 2), \"indicates\", ifelse(auc(roc_obj) > 0.8, \"good\", \"acceptable\"), \"discriminationnn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInterpretation: AUC of 0.73 indicates acceptable discriminationnn\n```\n\n\n:::\n:::\n\n\n## 6.3: Performance Across Multiple Thresholds\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Test three different thresholds\n\nthresholds_to_test <- c(0.3, 0.5, 0.7)\n\nthreshold_results <- map_df(thresholds_to_test, function(thresh) { # Generate predictions at this threshold\n  preds <- ifelse(test_data$predicted_prob > thresh, 1, 0)\n\n# Calculate confusion matrix\n  cm <- confusionMatrix(as.factor(preds),\n                        as.factor(test_data$recidivism),\n                        positive = \"1\")\n\n# Extract metrics\n  data.frame(threshold = thresh,\n             accuracy = cm$overall[\"Accuracy\"],\n             sensitivity = cm$byClass[\"Sensitivity\"],\n             specificity = cm$byClass[\"Specificity\"],\n             precision = cm$byClass[\"Precision\"],\n             f1_score = cm$byClass[\"F1\"],\n             # Calculate false positive and false negative rates\n             fpr = 1 - cm$byClass[\"Specificity\"],\n             fnr = 1 - cm$byClass[\"Sensitivity\"] ) })\n\n# Display results\n\nprint(threshold_results)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             threshold  accuracy sensitivity specificity precision  f1_score\nAccuracy...1       0.3 0.6476874   0.9686464   0.1685693 0.6349206 0.7670569\nAccuracy...2       0.5 0.6866127   0.8167219   0.4923896 0.7060379 0.7573573\nAccuracy...3       0.7 0.6209739   0.5034412   0.7964231 0.7868526 0.6140215\n                   fpr        fnr\nAccuracy...1 0.8314307 0.03135356\nAccuracy...2 0.5076104 0.18327810\nAccuracy...3 0.2035769 0.49655876\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualize threshold trade-offs\n\nthreshold_results %>%\n  select(threshold, sensitivity, specificity, precision) %>%\n  pivot_longer(cols = c(sensitivity, specificity, precision),\n               names_to = \"metric\",\n               values_to = \"value\") %>%\n  ggplot(aes(x = threshold,\n             y = value,\n             color = metric,\n             group = metric)\n         ) +\n  geom_line(size = 1.2\n            ) +\n  geom_point(size = 3\n             ) +\n  scale_color_brewer(palette = \"Set1\",\n                     labels = c(\"Precision\", \"Sensitivity\", \"Specificity\")\n                     ) +\n  scale_x_continuous(breaks = thresholds_to_test\n                     ) +\n  labs(title = \"Performance Metrics Across Thresholds\",\n       subtitle = \"The threshold-performance trade-off\",\n       x = \"Probability Threshold\",\n       y = \"Metric Value\",\n       color = \"Metric\"\n       ) +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n## CRITICAL INSIGHT:\n\nAs threshold increases:\n\n - Fewer people flagged as high-risk (more conservative)\n\n - Sensitivity decreases (miss more actual recidivists)\n\n - Specificity increases (fewer false accusations)\n\n - Precision usually increases (predictions more accurate when made)\n\n# PART 7: EQUITY ANALYSIS - GROUP-WISE PERFORMANCE\n\n## 7.1: Calculate Performance Metrics by Race\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# First, calculate overall metrics for comparison\n\noverall_metrics <- test_data %>%\n  summarise(Group = \"Overall\",\n            N = n(),\n            Base_Rate = mean(recidivism),\n            Sensitivity = sum(predicted_class_50 == 1 & recidivism == 1) / sum(recidivism == 1),\n            Specificity = sum(predicted_class_50 == 0 & recidivism == 0) / sum(recidivism == 0),\n            Precision = sum(predicted_class_50 == 1 & recidivism == 1) / sum(predicted_class_50 == 1),\n            FPR = sum(predicted_class_50 == 1 & recidivism == 0) / sum(recidivism == 0),\n            FNR = sum(predicted_class_50 == 0 & recidivism == 1) / sum(recidivism == 1))\n\n# Calculate metrics by race\n\nrace_metrics <- test_data %>%\n  group_by(Race) %>%\n  summarise(N = n(),\n            Base_Rate = mean(recidivism),\n            Sensitivity = sum(predicted_class_50 == 1 & recidivism == 1) / sum(recidivism == 1),\n            Specificity = sum(predicted_class_50 == 0 & recidivism == 0) / sum(recidivism == 0),\n            Precision = sum(predicted_class_50 == 1 & recidivism == 1) / sum(predicted_class_50 == 1),\n            FPR = sum(predicted_class_50 == 1 & recidivism == 0) / sum(recidivism == 0),\n            FNR = sum(predicted_class_50 == 0 & recidivism == 1) / sum(recidivism == 1) ) %>%\n  rename(Group = Race)\n\n# Combine overall and by-group metrics\n\nequity_analysis <- bind_rows(overall_metrics, race_metrics)\n\n# Display results\n\nprint(\"=\" %>% rep(80) %>% paste0(collapse = \"\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"================================================================================\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(\"EQUITY ANALYSIS: Model Performance by Race (Threshold = 0.5)\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"EQUITY ANALYSIS: Model Performance by Race (Threshold = 0.5)\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(\"=\" %>% rep(80) %>% paste0(collapse = \"\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"================================================================================\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(equity_analysis, width = Inf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 8\n  Group       N Base_Rate Sensitivity Specificity Precision   FPR   FNR\n  <chr>   <int>     <dbl>       <dbl>       <dbl>     <dbl> <dbl> <dbl>\n1 Overall  6551     0.599       0.817       0.492     0.706 0.508 0.183\n2 BLACK    3931     0.598       0.846       0.438     0.691 0.562 0.154\n3 WHITE    2620     0.600       0.773       0.575     0.732 0.425 0.227\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(\"=\" %>% rep(80) %>% paste0(collapse = \"\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"================================================================================\"\n```\n\n\n:::\n:::\n\n\n## 7.2: Visualize Disparate Impact\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create bar chart comparing key metrics across groups\n\nrace_metrics %>%\n  select(Group, FPR, FNR, Sensitivity, Specificity) %>%\n  pivot_longer(cols = c(FPR, FNR, Sensitivity, Specificity),\n               names_to = \"Metric\", values_to = \"Rate\") %>%\n  ggplot(aes(x = Group, y = Rate, fill = Metric)\n         ) +\n  geom_col(position = \"dodge\",\n           alpha = 0.8\n           ) +\n  scale_fill_brewer(palette = \"Set2\"\n                    ) +\n  labs(title = \"Model Performance Disparities Across Racial Groups\",\n       subtitle = \"Using threshold = 0.5\",\n       x = \"Race\",\n       y = \"Rate\",\n       fill = \"Metric\",\n       caption = \"FPR = False Positive Rate, FNR = False Negative Rate\"\n       ) +\n  theme(axis.text.x = element_text(angle = 45,\n                                   hjust = 1))\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## 7.3: Testing Threshold Adjustments for Equity\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Can we achieve more equitable outcomes by adjusting thresholds?\n\n# Function to calculate key rates at a given threshold\n\ncalc_rates_by_threshold <- function(data, threshold) {\n  data %>%\n    mutate(pred = ifelse(predicted_prob > threshold, 1, 0)) %>%\n    summarise( threshold = threshold,\n               FPR = sum(pred == 1 & recidivism == 0) / sum(recidivism == 0),\n               FNR = sum(pred == 0 & recidivism == 1) / sum(recidivism == 1),\n               Sensitivity = sum(pred == 1 & recidivism == 1) / sum(recidivism == 1),\n               Specificity = sum(pred == 0 & recidivism == 0) / sum(recidivism == 0) ) }\n\n# Test range of thresholds for each racial group\n\nthreshold_range <- seq(0.3, 0.7, by = 0.05)\n\nthreshold_by_race <- test_data %>%\n  nest_by(Race) %>%\n  reframe(map_df(threshold_range,\n                 ~calc_rates_by_threshold(data, .x))) %>%\n  ungroup()\n\n# Visualize FPR across thresholds by race\n\nggplot(threshold_by_race,\n       aes(x = threshold, y = FPR,color = Race)\n       ) +\n  geom_line(size = 1.2\n            ) +\n  geom_point(size = 2\n            ) +\n  geom_vline(xintercept = 0.5,\n             linetype = \"dashed\",\n             alpha = 0.5\n             ) +\n  labs(title = \"False Positive Rate by Threshold and Race\",\n       subtitle = \"Could different thresholds equalize FPR?\",\n       x = \"Probability Threshold\",\n       y = \"False Positive Rate\",\n       color = \"Race\")\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Visualize FNR across thresholds by race\n\nggplot(threshold_by_race,\n       aes(x = threshold, y = FNR, color = Race)\n       ) +\n  geom_line(size = 1.2\n            ) +\n  geom_point(size = 2\n             ) +\n  geom_vline(xintercept = 0.5,\n             linetype = \"dashed\",\n             alpha = 0.5\n             ) +\n  labs(title = \"False Negative Rate by Threshold and Race\",\n       subtitle = \"The trade-off: equalizing FPR may worsen FNR disparities\",\n       x = \"Probability Threshold\",\n       y = \"False Negative Rate\",\n       color = \"Race\")\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n:::\n\n\n# PART 8: SYNTHESIS AND RECOMMENDATIONS\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fill in the sections below.\n\ncat(\"\\n\")\n```\n\n```{.r .cell-code}\ncat(\"\\nKEY FINDINGS & POLICY IMPLICATIONSn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nKEY FINDINGS & POLICY IMPLICATIONSn\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n\\n\")\n```\n\n```{.r .cell-code}\ncat(\"1. MODEL PERFORMANCE:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1. MODEL PERFORMANCE:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - AUC:\", round(auc(roc_obj), 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - AUC: 0.732 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Overall accuracy at threshold = 0.5:\", round(cm_50$overall[\"Accuracy\"], 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Overall accuracy at threshold = 0.5: 0.687 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Interpretation: [Your assessment here]\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Interpretation: [Your assessment here]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"2. THRESHOLD TRADE-OFFS:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2. THRESHOLD TRADE-OFFS:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Lower threshold (0.3): Higher sensitivity, more false positives\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Lower threshold (0.3): Higher sensitivity, more false positives\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Higher threshold (0.7): Higher specificity, more false negatives\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Higher threshold (0.7): Higher specificity, more false negatives\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Decision depends on: relative costs of each error type\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Decision depends on: relative costs of each error type\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"3. EQUITY CONCERNS:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3. EQUITY CONCERNS:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - [Identify which groups face higher FPR or FNR]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - [Identify which groups face higher FPR or FNR]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - [Discuss potential causes: differential base rates, proxy variables]\\n\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - [Discuss potential causes: differential base rates, proxy variables]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - [Consider impossibility of perfect fairness when base rates differ]\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - [Consider impossibility of perfect fairness when base rates differ]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"4. DEPLOYMENT RECOMMENDATION:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n4. DEPLOYMENT RECOMMENDATION:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" Should this model be used for parole decisions?\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Should this model be used for parole decisions?\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Technical readiness: [Your assessment]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Technical readiness: [Your assessment]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Ethical considerations: [Your analysis]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Ethical considerations: [Your analysis]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Required safeguards: [Your recommendations]\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Required safeguards: [Your recommendations]\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\" - Alternatives: [Your suggestions]\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n - Alternatives: [Your suggestions]\n```\n\n\n:::\n:::\n\n\n# ADDITIONAL ANALYSES (OPTIONAL EXTENSIONS)\n\n## Extension 1: Calibration Analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check if predicted probabilities match actual outcomes\n\ntest_data %>%\n  mutate(prob_bin = cut(predicted_prob,\n                        breaks = seq(0, 1, by = 0.1))\n         ) %>%\n  group_by(prob_bin) %>%\n  summarise(mean_predicted = mean(predicted_prob),\n            mean_observed = mean(recidivism),\n            n = n() ) %>%\n  filter(n > 10) %>%\n  ggplot(aes(x = mean_predicted, y = mean_observed, size = n)\n         ) +\n  geom_point(alpha = 0.6, color = \"steelblue\"\n             ) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\"\n              ) +\n  labs(title = \"Calibration Plot\",\n       subtitle = \"Are predicted probabilities well-calibrated?\",\n       x = \"Mean Predicted Probability\",\n       y = \"Mean Observed Recidivism Rate\",\n       size = \"N in bin\"\n       ) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Extension 2: Feature Importance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Which variables matter most?\n\ncoef_df <- summary(logit_model)$coefficients %>%\n  as.data.frame() %>% rownames_to_column(\"variable\") %>%\n  mutate(odds_ratio = exp(Estimate)) %>%\n  filter(variable != \"(Intercept)\") %>%\n  arrange(desc(abs(Estimate)))\n\nggplot(coef_df,\n       aes(x = reorder(variable, Estimate),\n           y = odds_ratio)\n       ) +\n  geom_point(size = 3, color = \"steelblue\"\n             ) +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\"\n             ) +\n  coord_flip() +\n  scale_y_continuous(trans = \"log10\") +\n  labs(title = \"Feature Importance (Odds Ratios)\",\n       subtitle = \"OR > 1 increases recidivism risk; OR < 1 decreases risk\",\n       x = \"Variable\",\n       y = \"Odds Ratio (log scale)\")\n```\n\n::: {.cell-output-display}\n![](week-10-class-lab_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "week-10-class-lab_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}