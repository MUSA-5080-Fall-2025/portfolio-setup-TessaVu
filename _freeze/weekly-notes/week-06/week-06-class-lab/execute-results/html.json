{
  "hash": "260b3202c3c49e3b8c4d842741d44fa2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Spatial Machine Learning & Advanced Regression\"\nsubtitle: \"Week 6: MUSA 5080\"\nauthor: \"Dr. Elizabeth Delmelle\"\ndate: \"October 14, 2025\"\nformat: \n  revealjs:\n    theme: simple\n    slide-number: true\n    chalkboard: true\n    code-line-numbers: true\n    incremental: false\n    smaller: true\n    scrollable: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n# Today's Journey\n\n## What We'll Cover\n\n::::: columns\n::: {.column width=\"50%\"}\n**Warm-Up: Build a Baseline Model**\n\n-   Quick review of Week 5 regression\n-   Create simple structural model\n-   Identify its limitations\n\n**Part 1: Expanding Your Toolkit**\n\n-   Categorical variables\n-   Interactions\n-   Polynomial terms\n:::\n\n::: {.column width=\"50%\"}\n**Part 2: Why Space Matters**\n\n-   Hedonic model framework\n-   Tobler's First Law\n-   Spatial autocorrelation\n\n**Part 3: Creating Spatial Features**\n\n-   Buffer aggregation\n-   k-Nearest Neighbors\n-   Distance to amenities\n:::\n:::::\n\n**Part 4: Fixed Effects**\n\n------------------------------------------------------------------------\n\n# Warm-Up: Build a Baseline Model\n\n## Let's Build Something Simple Together\n\nWe'll start by creating a basic model using **only structural\nfeatures** - this will be our baseline to improve upon today.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages and data\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nhere() starts at C:/Users/Tess/Documents/GitHub/portfolio-setup-TessaVu/weekly-notes/week-06\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load Boston housing data\nboston <- read_csv(here(\"data/boston.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\nRows: 1485 Columns: 24\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(8): Style, R_AC, LU, OWN_OCC, R_BLDG_STY, R_ROOF_TYP, R_EXT_FIN, R_HEA... dbl\n(16): ...1, Parcel_No, SalePrice, PricePerSq, LivingArea, GROSS_AREA, NU...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n\n\n:::\n\n```{.r .cell-code}\n# Quick look at the data\nglimpse(boston)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 1,485\nColumns: 24\n$ ...1       <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ Parcel_No  <dbl> 100032000, 100058000, 100073000, 100112000, 100137000, 1001…\n$ SalePrice  <dbl> 450000, 600000, 450000, 670000, 260000, 355000, 665000, 355…\n$ PricePerSq <dbl> 228.89, 164.34, 105.98, 291.94, 217.21, 190.96, 227.35, 120…\n$ LivingArea <dbl> 1966, 3840, 4246, 2295, 1197, 1859, 2925, 2904, 892, 1916, …\n$ Style      <chr> \"Conventional\", \"Semi?Det\", \"Decker\", \"Row\\xa0End\", \"Coloni…\n$ GROSS_AREA <dbl> 3111, 5603, 6010, 3482, 1785, 2198, 4341, 3892, 1658, 3318,…\n$ NUM_FLOORS <dbl> 2.0, 3.0, 3.0, 3.0, 2.0, 1.5, 3.0, 3.0, 2.0, 2.0, 1.5, 2.0,…\n$ R_BDRMS    <dbl> 4, 8, 9, 6, 2, 3, 8, 6, 2, 2, 4, 3, 3, 3, 6, 8, 4, 4, 3, 2,…\n$ R_FULL_BTH <dbl> 2, 3, 3, 3, 1, 3, 3, 3, 1, 2, 2, 3, 1, 1, 3, 3, 2, 3, 1, 2,…\n$ R_HALF_BTH <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,…\n$ R_KITCH    <dbl> 2, 3, 3, 3, 1, 2, 3, 3, 1, 2, 2, 3, 1, 1, 3, 3, 2, 3, 2, 2,…\n$ R_AC       <chr> \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ R_FPLACE   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ LU         <chr> \"R2\", \"R3\", \"R3\", \"R3\", \"R1\", \"R2\", \"R3\", \"E\", \"R1\", \"R2\", …\n$ OWN_OCC    <chr> \"Y\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\",…\n$ R_BLDG_STY <chr> \"CV\", \"SD\", \"DK\", \"RE\", \"CL\", \"CV\", \"DK\", \"DK\", \"RE\", \"TF\",…\n$ R_ROOF_TYP <chr> \"H\", \"F\", \"F\", \"F\", \"F\", \"G\", \"F\", \"F\", \"G\", \"F\", \"G\", \"F\",…\n$ R_EXT_FIN  <chr> \"M\", \"B\", \"M\", \"M\", \"P\", \"M\", \"M\", \"A\", \"A\", \"M\", \"W\", \"W\",…\n$ R_TOTAL_RM <dbl> 10, 17, 20, 14, 5, 8, 14, 14, 4, 9, 7, 7, 5, 5, 15, 14, 11,…\n$ R_HEAT_TYP <chr> \"W\", \"W\", \"W\", \"W\", \"E\", \"E\", \"W\", \"W\", \"W\", \"W\", \"W\", \"W\",…\n$ YR_BUILT   <dbl> 1900, 1910, 1910, 1905, 1860, 1905, 1900, 1890, 1900, 1900,…\n$ Latitude   <dbl> 42.37963, 42.37877, 42.37940, 42.38014, 42.37967, 42.37953,…\n$ Longitude  <dbl> -71.03076, -71.02943, -71.02846, -71.02859, -71.02903, -71.…\n```\n\n\n:::\n\n```{.r .cell-code}\n# Simple model: Predict price from living area\nbaseline_model <- lm(SalePrice ~ LivingArea, data = boston)\nsummary(baseline_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = SalePrice ~ LivingArea, data = boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-855962 -219491  -68291   55248 9296561 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 157968.32   35855.59   4.406 1.13e-05 ***\nLivingArea     216.54      14.47  14.969  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 563800 on 1483 degrees of freedom\nMultiple R-squared:  0.1313,\tAdjusted R-squared:  0.1307 \nF-statistic: 224.1 on 1 and 1483 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## What Does This Model Tell Us?\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = SalePrice ~ LivingArea, data = boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-855962 -219491  -68291   55248 9296561 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 157968.32   35855.59   4.406 1.13e-05 ***\nLivingArea     216.54      14.47  14.969  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 563800 on 1483 degrees of freedom\nMultiple R-squared:  0.1313,\tAdjusted R-squared:  0.1307 \nF-statistic: 224.1 on 1 and 1483 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1312636\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Interpreting Our Baseline\n\n**Expected Output:**\n\n| Variable   | Coefficient | Std. Error | t-value | p-value |\n|------------|-------------|------------|---------|---------|\n| Intercept  | 157968.32   | 35855.59   | 4.406   | \\<0.001 |\n| LivingArea | 216.54      | 14.47      | 14.969  | \\<0.001 |\n\n**What this means:**\n\n-   Base price (0 sq ft) ≈ 157968.32\n-   Each additional square foot adds \\~216 to price\n-   Relationship is statistically significant (p \\< 0.001)\n-   But R² is only **0.13** (13% of variation explained)\n\n::: callout-important\n## The Problem\n\n**MOST of the variation in house prices is still unexplained!**\n\nWhat are we missing? 🤔\n:::\n\n------------------------------------------------------------------------\n\n## Limitations of This Model\n\n::: callout-warning\n## What's Missing?\n\n1.  **What does this model ignore?**\n    -   Location! (North End vs. Roxbury vs. Back Bay)\n    -   Proximity to downtown, waterfront, parks\n    -   Nearby crime levels\n    -   School quality\n    -   Neighborhood characteristics\n2.  **Why might it fail?**\n    -   1,000 sq ft in Back Bay ≠ 1,000 sq ft in Roxbury\n    -   Same house, different locations → vastly different prices\n    -   \"Location, location, location!\"\n3.  **How could we improve it?**\n    -   Add spatial features (crime nearby, distance to amenities)\n    -   Control for neighborhood (fixed effects)\n    -   Include interactions (does size matter more in wealthy areas?)\n:::\n\n**This is exactly where spatial features come in!**\n\n------------------------------------------------------------------------\n\n## Let's Add One More Feature\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add number of bathrooms\nbetter_model <- lm(SalePrice ~ LivingArea + R_FULL_BTH, data = boston)\nsummary(better_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = SalePrice ~ LivingArea + R_FULL_BTH, data = boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-783019 -230756  -65737   75367 9193133 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 107683.96   37340.88   2.884  0.00399 ** \nLivingArea     145.68      21.33   6.828 1.25e-11 ***\nR_FULL_BTH  106978.13   23800.30   4.495 7.50e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 560200 on 1482 degrees of freedom\nMultiple R-squared:  0.1429,\tAdjusted R-squared:  0.1418 \nF-statistic: 123.6 on 2 and 1482 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare models\ncat(\"Baseline R²:\", summary(baseline_model)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBaseline R²: 0.1312636 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"With bathrooms R²:\", summary(better_model)$r.squared, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWith bathrooms R²: 0.1429474 \n```\n\n\n:::\n:::\n\n\n**R² improves a smidge... but still missing location!**\n\n::: callout-note\n## Today's Goal\n\nBy the end of class, you'll build models that: - Incorporate spatial\nrelationships - Account for neighborhood effects\\\n- Achieve much better prediction accuracy - Help you understand what\ndrives housing prices\n:::\n\n------------------------------------------------------------------------\n\n## Converting to Spatial Data\n\n### Step 1: Make your data spatial\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n\n# Convert boston data to sf object\nboston.sf <- boston %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102286')  # MA State Plane (feet)\n\n# Check it worked\nhead(boston.sf)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 22 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 238643.6 ymin: 903246 xmax: 238833.2 ymax: 903399.5\nProjected CRS: NAD_1983_HARN_StatePlane_Massachusetts_Mainland_FIPS_2001\n# A tibble: 6 × 23\n   ...1 Parcel_No SalePrice PricePerSq LivingArea Style    GROSS_AREA NUM_FLOORS\n  <dbl>     <dbl>     <dbl>      <dbl>      <dbl> <chr>         <dbl>      <dbl>\n1     1 100032000    450000       229.       1966 \"Conven…       3111        2  \n2     2 100058000    600000       164.       3840 \"Semi?D…       5603        3  \n3     3 100073000    450000       106.       4246 \"Decker\"       6010        3  \n4     4 100112000    670000       292.       2295 \"Row\\xa…       3482        3  \n5     5 100137000    260000       217.       1197 \"Coloni…       1785        2  \n6     6 100138000    355000       191.       1859 \"Conven…       2198        1.5\n# ℹ 15 more variables: R_BDRMS <dbl>, R_FULL_BTH <dbl>, R_HALF_BTH <dbl>,\n#   R_KITCH <dbl>, R_AC <chr>, R_FPLACE <dbl>, LU <chr>, OWN_OCC <chr>,\n#   R_BLDG_STY <chr>, R_ROOF_TYP <chr>, R_EXT_FIN <chr>, R_TOTAL_RM <dbl>,\n#   R_HEAT_TYP <chr>, YR_BUILT <dbl>, geometry <POINT [m]>\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(boston.sf)  # Should show \"sf\" and \"data.frame\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n\n\n:::\n:::\n\n\n::: callout-tip\n### Why transform CRS?\n\n-   **4326** = WGS84 (lat/lon in degrees) - fine for display\n-   **ESRI:102286** = MA State Plane (feet) - good for distance\n    calculations\n:::\n\n------------------------------------------------------------------------\n\n## Step 2: Spatial Join with Neighborhoods\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load neighborhood boundaries\nnhoods <- read_sf(here(\"data/BPDA_Neighborhood_Boundaries.geojson\")) %>%\n  st_transform('ESRI:102286')  # Match CRS!\n\n# Check the neighborhoods\nhead(nhoods)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 229049.1 ymin: 890856 xmax: 236590.9 ymax: 900302.5\nProjected CRS: NAD_1983_HARN_StatePlane_Massachusetts_Mainland_FIPS_2001\n# A tibble: 6 × 8\n  sqmiles name         neighborhood_id  acres SHAPE__Length objectid SHAPE__Area\n    <dbl> <chr>        <chr>            <dbl>         <dbl>    <int>       <dbl>\n1    2.51 Roslindale   15              1606.         53564.       53   69938273.\n2    3.94 Jamaica Pla… 11              2519.         56350.       54  109737890.\n3    0.55 Mission Hill 13               351.         17919.       55   15283120.\n4    0.29 Longwood     28               189.         11909.       56    8215904.\n5    0.04 Bay Village  33                26.5         4651.       57    1156071.\n6    0.02 Leather Dis… 27                15.6         3237.       58     681272.\n# ℹ 1 more variable: geometry <MULTIPOLYGON [m]>\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(nhoods)  # How many neighborhoods?\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 26\n```\n\n\n:::\n\n```{.r .cell-code}\n# Spatial join: Assign each house to its neighborhood\nboston.sf <- boston.sf %>%\n  st_join(nhoods, join = st_intersects)\n\n# Check results\nboston.sf %>%\n  st_drop_geometry() %>%\n  count(name) %>%\n  arrange(desc(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 19 × 2\n   name              n\n   <chr>         <int>\n 1 Dorchester      344\n 2 West Roxbury    242\n 3 Hyde Park       152\n 4 East Boston     149\n 5 Roslindale      142\n 6 Jamaica Plain   113\n 7 South Boston     80\n 8 Charlestown      65\n 9 Mattapan         65\n10 Roxbury          63\n11 South End        20\n12 Beacon Hill      17\n13 Mission Hill     14\n14 Allston           6\n15 Brighton          6\n16 Back Bay          3\n17 Fenway            2\n18 Bay Village       1\n19 Downtown          1\n```\n\n\n:::\n:::\n\n\n::: callout-important\n### What just happened?\n\n`st_join()` found which neighborhood polygon contains each house point!\n:::\n\n------------------------------------------------------------------------\n\n## Visualize: Prices by Neighborhood\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## The Spatial Pattern is Clear!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Which neighborhoods are most expensive?\nprice_by_nhood %>%\n  arrange(desc(median_price)) %>%\n  head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n  name        median_price n_sales\n  <chr>              <dbl>   <int>\n1 Back Bay         9500000       3\n2 Beacon Hill      2892750      17\n3 South End        2797500      20\n4 Bay Village      2300000       1\n5 Fenway           2112500       2\n```\n\n\n:::\n\n```{.r .cell-code}\n# Which have most sales?\nprice_by_nhood %>%\n  arrange(desc(n_sales)) %>%\n  head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 3\n  name         median_price n_sales\n  <chr>               <dbl>   <int>\n1 Dorchester         511250     344\n2 West Roxbury       503750     242\n3 Hyde Park          390000     152\n4 East Boston        463000     149\n5 Roslindale         489500     142\n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Discussion Question\n\nWhy do you think certain neighborhoods command higher prices? -\nProximity to downtown? - Historical character? - School quality? -\nSafety? - All of the above?\n\n**This is why we need spatial features and neighborhood controls!**\n:::\n\n------------------------------------------------------------------------\n\n# Part 1: Expanding Your Regression Toolkit {background-color=\"#667eea\"}\n\n------------------------------------------------------------------------\n\n## Beyond Continuous Variables\n\n::::: columns\n::: {.column width=\"50%\"}\n### ✅ Continuous Variables\n\n-   Square footage\n-   Age of house\n-   Income levels\n-   Distance to downtown\n:::\n\n::: {.column width=\"50%\"}\n### 🏷️ Categorical Variables\n\n-   Neighborhood\n-   School district\n-   Building type\n-   Has garage? (Yes/No)\n:::\n:::::\n\n------------------------------------------------------------------------\n\n## Dummy Variables\n\n### Our Boston Data: `name` variable from spatial join\n\nNeighborhoods in our dataset (showing just a few):\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 2\n   name              n\n   <chr>         <int>\n 1 Dorchester      344\n 2 West Roxbury    242\n 3 Hyde Park       152\n 4 East Boston     149\n 5 Roslindale      142\n 6 Jamaica Plain   113\n 7 South Boston     80\n 8 Charlestown      65\n 9 Mattapan         65\n10 Roxbury          63\n```\n\n\n:::\n:::\n\n\n**How R Handles This**\n\nWhen you include `name` in a model, R automatically creates binary\nindicators:\n\n-   **Back_Bay:** 1 if Back Bay, 0 otherwise\n-   **Beacon_Hill:** 1 if Beacon Hill, 0 otherwise\n-   **Charlestown:** 1 if Charlestown, 0 otherwise\n-   ...and so on for all neighborhoods\n\n::: callout-warning\n### ⚠️ The (n-1) Rule\n\nOne neighborhood is automatically chosen as the **reference category**\n(omitted)!\n\nR picks the first alphabetically unless you specify otherwise.\n:::\n\n------------------------------------------------------------------------\n\n## Add Dummy (Categorical) Variables to the Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Ensure name is a factor\nboston.sf <- boston.sf %>%\n  mutate(name = as.factor(name))\n\n# Check which is reference (first alphabetically)\nlevels(boston.sf$name)[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Allston\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fit model with neighborhood fixed effects\nmodel_neighborhoods <- lm(SalePrice ~ LivingArea + name, \n                          data = boston.sf)\n\n# Show just first 10 coefficients\nsummary(model_neighborhoods)$coef[1:10, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    Estimate   Std. Error    t value      Pr(>|t|)\n(Intercept)      704306.0751 9.022210e+04  7.8063584  1.112892e-14\nLivingArea          138.3206 6.468186e+00 21.3847638  1.605175e-88\nnameBack Bay    7525585.0560 1.533714e+05 49.0677253 1.522921e-311\nnameBay Village 1284057.5326 2.320256e+05  5.5341206  3.700442e-08\nnameBeacon Hill 1767805.2297 1.020211e+05 17.3278366  2.465874e-61\nnameBrighton    -168941.2113 1.239972e+05 -1.3624597  1.732623e-01\nnameCharlestown   -2556.8667 9.208989e+04 -0.0277649  9.778534e-01\nnameDorchester  -576819.4858 8.846990e+04 -6.5199517  9.653393e-11\nnameDowntown      58553.1237 2.322150e+05  0.2521505  8.009601e-01\nnameEast Boston -534060.4110 8.962950e+04 -5.9585340  3.182615e-09\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n------------------------------------------------------------------------\n\n## Interpreting Neighborhood Dummy Variables\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Variable                | Coefficient|    p-value|\n|:-----------------------|-----------:|----------:|\n|Intercept (Allston)     |    $649,635| < 0.001***|\n|Living Area (per sq ft) |        $114| < 0.001***|\n|Back Bay                |  $7,561,273| < 0.001***|\n|Beacon Hill             |  $1,780,861| < 0.001***|\n|Charlestown             |     $22,575|      0.806|\n|Dorchester              |   -$540,267| < 0.001***|\n|East Boston             |   -$515,990| < 0.001***|\n|Roxbury                 |   -$566,534| < 0.001***|\n\n\n:::\n:::\n\n\n### How to Read This Table\n\n**Reference Category:** Allston (automatically chosen - alphabetically\nfirst)\n\n**Structural Variables:**\n\n-   **Living Area:** Each additional sq ft adds this amount (same for\n    all neighborhoods)\n-   **Bedrooms:** Effect of one more full bathroom (same for all\n    neighborhoods)\n\n**Neighborhood Dummies:**\n\n-   **Positive coefficient** = This neighborhood is MORE expensive than\n    Allston\n-   **Negative coefficient** = This neighborhood is LESS expensive than\n    Allston\n-   All else equal (same size, same bathrooms)\n\n------------------------------------------------------------------------\n\n## Concrete Example: Comparing Two Houses\n\nUsing our model, let's compare identical houses in different\nneighborhoods:\n\n::::: columns\n::: {.column width=\"50%\"}\n### House A: Back Bay\n\n-   Living Area: 1,500 sq ft\n-   Baths: 2\n-   **Neighborhood:** Back Bay\n\n**Predicted Price:**\n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n           1 \n\"$8,458,873\" \n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n### House B: Roxbury\n\n-   Living Area: 1,500 sq ft\n-   Baths: 2\n-   **Neighborhood:** Roxbury\n\n**Predicted Price:**\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n         1 \n\"$331,066\" \n```\n\n\n:::\n:::\n\n:::\n:::::\n\n::: callout-important\nThe Neighborhood Effect Price Difference\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n           1 \n\"$8,127,807\" \n```\n\n\n:::\n:::\n\n\nSame house, different location = huge price difference! This is what the\nneighborhood dummies capture.\n:::\n\n------------------------------------------------------------------------\n\n## Interaction Effects: When Relationships Depend\n\n### The Question\n\nDoes the effect of one variable **depend on** the level of another\nvariable?\n\n### Example Scenarios\n\n-   **Housing:** Does square footage matter more in wealthy\n    neighborhoods?\n-   **Education:** Do tutoring effects vary by initial skill level?\n-   **Public Health:** Do pollution effects differ by age?\n\n::: callout-important\n### Mathematical Form\n\nSalePrice = β₀ + β₁(LivingArea) + β₂(WealthyNeighborhood) +\n**β₃(LivingArea × WealthyNeighborhood)** + ε\n:::\n\n**Today's example:** Is the value of square footage the same across all\nBoston neighborhoods?\n\n------------------------------------------------------------------------\n\n## Theory: Luxury Premium Hypothesis\n\n::::: columns\n::: {.column width=\"50%\"}\n### 🏛️ In Wealthy Neighborhoods\n\n(Back Bay, Beacon Hill, South End)\n\n-   High-end buyers pay premium for space\n-   Luxury finishes, location prestige\n-   Each sq ft adds substantial value\n-   **Steep slope**\n\n**Hypothesis:** \\$300+ per sq ft\n:::\n\n::: {.column width=\"50%\"}\n### 🏘️ In Working-Class Neighborhoods\n\n(Dorchester, Mattapan, East Boston)\n\n-   Buyers value function over luxury\n-   More price-sensitive market\n-   Space matters, but less premium\n-   **Flatter slope**\n\n**Hypothesis:** \\$100-150 per sq ft\n:::\n:::::\n\n::: callout-note\n### The Key Question\n\nIf we assume one slope for all neighborhoods, are we misunderstanding\nthe market?\n:::\n\n------------------------------------------------------------------------\n\n## Create the Neighborhood Categories\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define wealthy neighborhoods based on median prices\nwealthy_hoods <- c(\"Back Bay\", \"Beacon Hill\", \"South End\", \"Bay Village\")\n\n# Create binary indicator\nboston.sf <- boston.sf %>%\n  mutate(\n    wealthy_neighborhood = ifelse(name %in% wealthy_hoods, \"Wealthy\", \"Not Wealthy\"),\n    wealthy_neighborhood = as.factor(wealthy_neighborhood)\n  )\n\n# Check the split\nboston.sf %>%\n  st_drop_geometry() %>%\n  count(wealthy_neighborhood)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  wealthy_neighborhood     n\n  <fct>                <int>\n1 Not Wealthy           1444\n2 Wealthy                 41\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Model 1: No Interaction (Parallel Slopes)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model assumes same slope everywhere\nmodel_no_interact <- lm(SalePrice ~ LivingArea + wealthy_neighborhood, \n                        data = boston.sf)\n\nsummary(model_no_interact)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                Estimate   Std. Error   t value      Pr(>|t|)\n(Intercept)                  213842.7642 23893.619394  8.949785  1.039392e-18\nLivingArea                      160.2357     9.713346 16.496442  2.936087e-56\nwealthy_neighborhoodWealthy 2591012.0471 59958.794614 43.213211 1.103579e-264\n```\n\n\n:::\n:::\n\n\n::: callout-warning\nWhat This Assumes\n\nLiving area has the same effect in all neighborhoods Only the intercept\ndiffers (wealthy areas start higher) Parallel lines on a plot\n:::\n\n------------------------------------------------------------------------\n\n## Model 2: With Interaction (Different Slopes)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model allows different slopes\nmodel_interact <- lm(SalePrice ~ LivingArea * wealthy_neighborhood, \n                     data = boston.sf)\n\nsummary(model_interact)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                            Estimate   Std. Error   t value\n(Intercept)                             358542.41696 1.863997e+04 19.235144\nLivingArea                                  95.63947 7.620382e+00 12.550483\nwealthy_neighborhoodWealthy            -377937.38372 1.005554e+05 -3.758498\nLivingArea:wealthy_neighborhoodWealthy     985.12500 2.975904e+01 33.103383\n                                            Pr(>|t|)\n(Intercept)                             8.875710e-74\nLivingArea                              2.079700e-34\nwealthy_neighborhoodWealthy             1.775774e-04\nLivingArea:wealthy_neighborhoodWealthy 2.445570e-180\n```\n\n\n:::\n:::\n\n\n::: callout-important\nWhat This Allows\n\nLiving area can have different effects in different neighborhoods Both\nintercept AND slope differ Non-parallel lines on a plot\n:::\n\n------------------------------------------------------------------------\n\n## Interpreting the Interaction Coefficients\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Term                           | Coefficient| t-value| p-value| Sig |\n|:------------------------------|-----------:|-------:|-------:|:---:|\n|Intercept (Not Wealthy)        |    $358,542|  19.235|       0| *** |\n|Living Area (Not Wealthy)      |         $96|  12.550|       0| *** |\n|Wealthy Neighborhood Premium   |   -$377,937|  -3.758|       0| *** |\n|Extra $/sq ft in Wealthy Areas |        $985|  33.103|       0| *** |\n\n\n:::\n:::\n\n\n*We get the un-intuitive negative premium here because that is an\nintercept adjustment (applies at 0 sqft). The slope difference\n(+985sq/ft) is huge - we can calculate when wealthy areas become more\nexpensive (at what sq ft) = 384.*\n\n------------------------------------------------------------------------\n\n## Breaking Down the Coefficients\n\n\n::: {.cell}\n\n:::\n\n\n::::: columns\n::: {.column width=\"50%\"}\n🏘️ Not Wealthy Areas Equation: Price =\n$358,542 +\n$96 × LivingArea\nInterpretation:\n\nBase price: $358,542 Each sq ft\nadds: $96\n:::\n\n::: {.column width=\"50%\"}\n🏛️ Wealthy Areas Equation: Price =\n-$19,395 +\n$1,081 × LivingArea\nInterpretation:\n\nBase price: -$19,395 Each sq\nft adds: $1,081\n:::\n:::::\n\n::: callout-important\nThe Interaction Effect Wealthy areas value each sq ft\n$985 more than\nnon-wealthy areas!\n:::\n\n------------------------------------------------------------------------\n\n## Visualizing the Interaction Effect\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\nKey Observation: The lines are NOT parallel - that's the interaction!\n\n------------------------------------------------------------------------\n\n## Compare Model Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare R-squared\ncat(\"Model WITHOUT interaction R²:\", round(summary(model_no_interact)$r.squared, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel WITHOUT interaction R²: 0.6156 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Model WITH interaction R²:\", round(summary(model_interact)$r.squared, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel WITH interaction R²: 0.7791 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Improvement:\", round(summary(model_interact)$r.squared - summary(model_no_interact)$r.squared, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImprovement: 0.1635 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n::: callout-important\nModel Improvement Adding the interaction improves R² by\n0.1635 (a 26.6%\nrelative improvement)\n\nInterpretation: We explain 16.35% more\nvariation in prices by allowing different slopes!\n:::\n\n------------------------------------------------------------------------\n\n## Policy Implications\n\n::: callout-warning\n## What This Tells Us About Boston's Housing Market\n\n1.  Market Segmentation: Boston operates as TWO distinct housing markets\n\n-   Luxury market: Every sq ft is premium\n    (\\$1081/sq ft)\n-   Standard market: Space valued, but lower premium\n    (\\$96/sq ft)\n\n2.  Affordability Crisis: The interaction amplifies inequality\n\n-   Large homes in wealthy areas become exponentially more expensive\n-   Creates barriers to mobility between neighborhoods\n\n3.  Policy Design: One-size-fits-all policies may fail\n\n-   Property tax assessments should account for neighborhood-specific\n    valuation\n-   Housing assistance needs vary dramatically by area\n:::\n\n------------------------------------------------------------------------\n\n## When Not To Use Interactions\n\n::: callout-warning\nWhen NOT to Use Interactions:\n\n-   Small samples: Need sufficient data in each group\n-   Overfitting: Too many interactions make models unstable\n:::\n\n------------------------------------------------------------------------\n\n## Polynomial Terms: Non-Linear Relationships\n\n### When Straight Lines Don't Fit\n\n::::: columns\n::: {.column width=\"50%\"}\n**Signs of Non-Linearity:**\n\n-   Curved residual plots\n-   Diminishing returns\n-   Accelerating effects\n-   U-shaped or inverted-U patterns\n-   Theoretical reasons\n:::\n\n::: {.column width=\"50%\"}\n**Examples:**\n\n-   House age: depreciation then vintage premium\n-   Test scores: plateau after studying\n-   Advertising: diminishing returns\n-   Crime prevention: early gains, then plateaus\n:::\n:::::\n\n::: callout-important\n### Polynomial Regression\n\nSalePrice = β₀ + β₁(Age) + β₂(Age²) + ε\n\nThis allows for a **curved relationship**\n:::\n\n------------------------------------------------------------------------\n\n## Theory: The U-Shaped Age Effect\n\n### Why Would Age Have a Non-Linear Effect?\n\n:::::: columns\n::: {.column width=\"33%\"}\n### 🏗️ New Houses\n\n(0-20 years)\n\n-   Modern amenities\n-   Move-in ready\n-   No repairs needed\n-   **High value**\n-   Steep depreciation initially\n:::\n\n::: {.column width=\"33%\"}\n### 🏠 Middle-Aged\n\n(20-80 years)\n\n-   Needs updates\n-   Wear and tear\n-   Not yet \"historic\"\n-   **Lowest value**\n-   Trough of the curve\n:::\n\n::: {.column width=\"33%\"}\n### 🏛️ Historic/Vintage\n\n(80+ years)\n\n-   Architectural character\n-   Historic districts\n-   Prestige value\n-   **Rising value**\n-   \"Vintage premium\"\n:::\n::::::\n\n::: callout-note\n### Boston Context\n\nBoston has LOTS of historic homes (Back Bay, Beacon Hill built\n1850s-1900s). Does age create a U-shaped curve?\n:::\n\n## Create Age Variable\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate age from year built\nboston.sf <- boston.sf %>%\n  mutate(Age = 2025 - YR_BUILT)%>% filter(Age <2000)\n\n\n# Check the distribution of age\nsummary(boston.sf$Age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   12.0    95.0   115.0   108.1   125.0   223.0 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualize age distribution\nggplot(boston.sf, aes(x = Age)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"Distribution of House Age in Boston\",\n       x = \"Age (years)\",\n       y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## First: Linear Model (Baseline)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple linear relationship\nmodel_age_linear <- lm(SalePrice ~ Age + LivingArea, data = boston.sf)\n\nsummary(model_age_linear)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                Estimate  Std. Error   t value     Pr(>|t|)\n(Intercept) -120808.8738 57836.98918 -2.088782 3.689911e-02\nAge            2834.0198   497.72013  5.694003 1.496246e-08\nLivingArea      202.8312    15.10373 13.429214 7.228187e-39\n```\n\n\n:::\n:::\n\n\nInterpretation: Each additional year of age changes price by \\$2834.01\n(assumed constant rate)\n\n------------------------------------------------------------------------\n\n## Visualize: Is the relationship Linear?\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-26-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Add Polynomial Term: Age Squared\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Quadratic model (Age²)\nmodel_age_quad <- lm(SalePrice ~ Age + I(Age^2) + LivingArea, data = boston.sf)\n\nsummary(model_age_quad)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                Estimate   Std. Error   t value     Pr(>|t|)\n(Intercept) 570397.14406 97894.237962  5.826667 6.938345e-09\nAge         -13007.51918  1896.446156 -6.858892 1.019524e-11\nI(Age^2)        80.88988     9.360652  8.641479 1.425208e-17\nLivingArea     203.75007    14.739041 13.823835 5.975020e-41\n```\n\n\n:::\n:::\n\n\n::: callout-important\nThe I() Function Why I(Age\\^2) instead of just Age\\^2? In R formulas, \\^\nhas special meaning. I() tells R: \"interpret this literally, compute\nAge²\" Without I(): R would interpret it differently in the formula\n:::\n\n------------------------------------------------------------------------\n\n## Interpreting Polynomial Coefficients\n\n\n::: {.cell}\n\n:::\n\n\nModel equation: Price =\n$570,397 +\n-$13,008×Age +\n$80×Age² +\n$204×LivingArea\n\n::: callout-warning\n⚠️ Can't Interpret Coefficients Directly!\n\nWith Age², the effect of age is no longer constant. You need to\ncalculate the marginal effect. Marginal effect of Age = β₁ + 2×β₂×Age\nThis means the effect changes at every age!\n:::\n\n------------------------------------------------------------------------\n\n## Compare Model Performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# R-squared comparison\nr2_linear <- summary(model_age_linear)$r.squared\nr2_quad <- summary(model_age_quad)$r.squared\n\ncat(\"Linear model R²:\", round(r2_linear, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear model R²: 0.1549 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Quadratic model R²:\", round(r2_quad, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQuadratic model R²: 0.1959 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Improvement:\", round(r2_quad - r2_linear, 4), \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImprovement: 0.0409 \n```\n\n\n:::\n\n```{.r .cell-code}\n# F-test: Is the Age² term significant?\nanova(model_age_linear, model_age_quad)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nModel 1: SalePrice ~ Age + LivingArea\nModel 2: SalePrice ~ Age + I(Age^2) + LivingArea\n  Res.Df        RSS Df  Sum of Sq      F    Pr(>F)    \n1   1469 4.5786e+14                                   \n2   1468 4.3569e+14  1 2.2163e+13 74.675 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Check Residual Plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare residual plots\npar(mfrow = c(1, 2))\n\n# Linear model residuals\nplot(fitted(model_age_linear), residuals(model_age_linear),\n     main = \"Linear Model Residuals\",\n     xlab = \"Fitted Values\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\", lty = 2)\n\n# Quadratic model residuals  \nplot(fitted(model_age_quad), residuals(model_age_quad),\n     main = \"Quadratic Model Residuals\",\n     xlab = \"Fitted Values\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-30-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Part 3: Creating Spatial Features {background-color=\"#667eea\"}\n\n------------------------------------------------------------------------\n\n## Why Space Matters for Housing Prices\n\n### Tobler's First Law of Geography\n\n::: {.callout-note icon=\"false\" appearance=\"simple\"}\n# \"Everything is related to everything else, but near things are more related than distant things\"\n\n*- Waldo Tobler, 1970*\n:::\n\n### What This Means for House Prices\n\n-   Crime **nearby** matters more than crime across the city\n-   Parks **within walking distance** affect value\n-   Your **immediate neighborhood** defines your market\n\n::: callout-important\n### The Challenge\n\nHow do we quantify \"nearbyness\" in a way our regression model can use?\n\n**Answer:** Create spatial features that measure proximity to\namenities/disamenities\n:::\n\n------------------------------------------------------------------------\n\n## Three Approaches to Spatial Features\n\n### 1️⃣ Buffer Aggregation\n\n**Count or sum** events within a defined distance\n\n*Example: Number of crimes within 500 feet*\n\n### 2️⃣ k-Nearest Neighbors (kNN)\n\n**Average distance** to k closest events\n\n*Example: Average distance to 3 nearest violent crimes*\n\n### 3️⃣ Distance to Specific Points\n\n**Straight-line distance** to important locations\n\n*Example: Distance to downtown, nearest T station*\n\n::: callout-tip\n**Today:** We'll create all three types using Boston crime data!\n:::\n\n------------------------------------------------------------------------\n\n## Load and Prepare Crime Data\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\nNew names:\nRows: 200977 Columns: 21\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(9): STREET, OFFENSE_DESCRIPTION, SHOOTING, DISTRICT, DAY_OF_WEEK, INC... dbl\n(11): ...1, OFFENSE_CODE, REPORTING_AREA, MONTH, HOUR, X_full_count, Lo... dttm\n(1): OCCURRED_ON_DATE\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 200,977\nColumns: 21\n$ ...1                <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…\n$ STREET              <chr> \"ALBERT ST\", \"ALBERT ST\", \"L ST\", \"HAROLD ST\", \"BL…\n$ OFFENSE_DESCRIPTION <chr> \"DRUGS - POSS CLASS B - INTENT TO MFR DIST DISP\", …\n$ SHOOTING            <chr> NA, NA, NA, \"Y\", NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ OFFENSE_CODE        <dbl> 1843, 1841, 2900, 413, 3111, 2900, 3402, 1841, 311…\n$ DISTRICT            <chr> \"B2\", \"B2\", \"C6\", \"B2\", \"B3\", \"B3\", \"A1\", \"D4\", \"E…\n$ REPORTING_AREA      <dbl> NA, NA, 230, 314, 465, 406, 76, 270, 499, 356, 170…\n$ OCCURRED_ON_DATE    <dttm> 2015-08-01 23:07:00, 2015-08-01 23:07:00, 2015-08…\n$ DAY_OF_WEEK         <chr> \"Saturday\", \"Saturday\", \"Saturday\", \"Saturday\", \"S…\n$ MONTH               <dbl> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,…\n$ HOUR                <dbl> 23, 23, 8, 18, 1, 1, 1, 17, 15, 13, 19, 12, 1, 1, …\n$ X_full_count        <dbl> 273, 273, 273, 273, 273, 273, 273, 273, 273, 273, …\n$ Long                <dbl> NA, NA, -71.03529, -71.09072, -71.09104, -71.07442…\n$ YEAR                <dbl> 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 20…\n$ Lat                 <dbl> NA, NA, 42.33271, 42.31532, 42.28582, 42.27130, 42…\n$ INCIDENT_NUMBER     <chr> \"I152063654\", \"I152063654\", \"I152063493\", \"I152063…\n$ rank                <dbl> 0.314183, 0.314366, 0.314974, 0.315240, 0.315467, …\n$ X_id                <dbl> 243806, 243805, 243949, 243858, 244025, 244015, 24…\n$ OFFENSE_CODE_GROUP  <chr> \"Drug Violation\", \"Drug Violation\", \"Other\", \"Aggr…\n$ UCR_PART            <chr> \"Part Two\", \"Part Two\", \"Part Two\", \"Part One\", \"P…\n$ Location            <chr> \"(0.00000000, 0.00000000)\", \"(0.00000000, 0.000000…\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `BPDA_Neighborhood_Boundaries' from data source \n  `C:\\Users\\Tess\\Documents\\GitHub\\portfolio-setup-TessaVu\\weekly-notes\\week-06\\data\\BPDA_Neighborhood_Boundaries.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 26 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -71.19125 ymin: 42.22792 xmax: -70.92278 ymax: 42.39699\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    xmin     ymin     xmax     ymax \n227125.8 886966.0 241483.7 904797.2 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    xmin     ymin     xmax     ymax \n226505.0 887148.3 241435.5 904894.0 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    xmin     ymin     xmax     ymax \n225465.6 886449.8 247575.8 905284.0 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRecords with missing coordinates: 10103 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nViolent crime records: 39854 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 × 2\n  OFFENSE_CODE_GROUP             n\n  <chr>                      <int>\n1 Larceny                    16485\n2 Larceny From Motor Vehicle  7899\n3 Aggravated Assault          4618\n4 Residential Burglary        4263\n5 Robbery                     3083\n6 Auto Theft                  2380\n7 Commercial Burglary          754\n8 Other Burglary               286\n9 Homicide                      86\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Visaulize: Crime Locations\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-32-1.png){width=960}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Approach 1: Buffer Aggregation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create buffer features - these will work now that CRS is correct\nboston.sf <- boston.sf %>%\n  mutate(\n    crimes.Buffer = lengths(st_intersects(\n      st_buffer(geometry, 660),\n      crimes.sf\n    )),\n    crimes_500ft = lengths(st_intersects(\n      st_buffer(geometry, 500),\n      crimes.sf\n    ))\n  )\n\n# Check it worked\n#summary(boston.sf$crimes.Buffer)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Approach 2: k-Nearest Neighborhoods Method\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate distance matrix (houses to crimes)\ndist_matrix <- st_distance(boston.sf, crimes.sf)\n\n# Function to get mean distance to k nearest neighbors\nget_knn_distance <- function(dist_matrix, k) {\n  apply(dist_matrix, 1, function(distances) {\n    # Sort and take first k, then average\n    mean(as.numeric(sort(distances)[1:k]))\n  })\n}\n\n# Create multiple kNN features\nboston.sf <- boston.sf %>%\n  mutate(\n    crime_nn1 = get_knn_distance(dist_matrix, k = 1),\n    crime_nn3 = get_knn_distance(dist_matrix, k = 3),\n    crime_nn5 = get_knn_distance(dist_matrix, k = 5)\n  )\n\n# Check results\nsummary(boston.sf %>% st_drop_geometry() %>% select(starts_with(\"crime_nn\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   crime_nn1         crime_nn3         crime_nn5     \n Min.   :  9.372   Min.   :  9.372   Min.   : 10.67  \n 1st Qu.: 29.944   1st Qu.: 37.615   1st Qu.: 44.30  \n Median : 54.036   Median : 62.835   Median : 70.27  \n Mean   : 70.750   Mean   : 83.298   Mean   : 94.66  \n 3rd Qu.: 90.145   3rd Qu.:107.735   3rd Qu.:127.14  \n Max.   :596.529   Max.   :637.559   Max.   :683.53  \n```\n\n\n:::\n:::\n\n\n::: callout-note\nInterpretation: crime_nn3 = 83.29 means the average distance to the 3\nnearest crimes is 83.29 feet\n:::\n\n------------------------------------------------------------------------\n\n## Which k value correlates most with price?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Which k value correlates most with price?\nboston.sf %>%\n  st_drop_geometry() %>%\n  select(SalePrice, crime_nn1, crime_nn3, crime_nn5) %>%\n  cor(use = \"complete.obs\") %>%\n  as.data.frame() %>%\n  select(SalePrice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            SalePrice\nSalePrice  1.00000000\ncrime_nn1 -0.07317564\ncrime_nn3 -0.08726806\ncrime_nn5 -0.09599580\n```\n\n\n:::\n:::\n\n\n::: callout-tip\nFinding: The kNN feature with the strongest correlation tells us the\nrelevant \"zone of influence\" for crime perception!\n:::\n\n------------------------------------------------------------------------\n\nApproach 3: Distance to Downtown\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define downtown Boston (Boston Common: 42.3551° N, 71.0656° W)\ndowntown <- st_sfc(st_point(c(-71.0656, 42.3551)), crs = \"EPSG:4326\") %>%\n  st_transform('ESRI:102286')\n\n# Calculate distance from each house to downtown\nboston.sf <- boston.sf %>%\n  mutate(\n    dist_downtown_ft = as.numeric(st_distance(geometry, downtown)),\n    dist_downtown_mi = dist_downtown_ft / 5280\n  )\n\n# Summary\nsummary(boston.sf$dist_downtown_mi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.05467 0.80699 1.37601 1.39335 1.94227 2.77678 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### All spatial features together\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Summary of all spatial features created\nspatial_summary <- boston.sf %>%\n  st_drop_geometry() %>%\n  select(crimes.Buffer, crimes_500ft, crime_nn3, dist_downtown_mi) %>%\n  summary()\n\nspatial_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n crimes.Buffer     crimes_500ft      crime_nn3       dist_downtown_mi \n Min.   :   4.0   Min.   :   0.0   Min.   :  9.372   Min.   :0.05467  \n 1st Qu.: 105.0   1st Qu.:  63.0   1st Qu.: 37.615   1st Qu.:0.80699  \n Median : 323.0   Median : 188.0   Median : 62.835   Median :1.37601  \n Mean   : 440.2   Mean   : 261.9   Mean   : 83.298   Mean   :1.39335  \n 3rd Qu.: 737.0   3rd Qu.: 427.0   3rd Qu.:107.735   3rd Qu.:1.94227  \n Max.   :3108.0   Max.   :2088.0   Max.   :637.559   Max.   :2.77678  \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|Feature               |Type           |What it Measures                      |\n|:---------------------|:--------------|:-------------------------------------|\n|crimes.Buffer (660ft) |Buffer count   |Number of crimes near house           |\n|crimes_500ft          |Buffer count   |Crimes within 500ft                   |\n|crime_nn3             |kNN distance   |Avg distance to 3 nearest crimes (ft) |\n|dist_downtown_mi      |Point distance |Miles from downtown Boston            |\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n### Model Comparison: Adding Spatial Features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboston.sf <- boston.sf %>%\n  mutate(Age = 2015 - YR_BUILT)  \n\n# Model 1: Structural only\nmodel_structural <- lm(SalePrice ~ LivingArea + R_BDRMS + Age, \n                       data = boston.sf)\n\n# Model 2: Add spatial features\nmodel_spatial <- lm(SalePrice ~ LivingArea + R_BDRMS + Age +\n                    crimes_500ft + crime_nn3 + dist_downtown_mi,\n                    data = boston.sf)\n\n# Compare\ncat(\"Structural R²:\", round(summary(model_structural)$r.squared, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStructural R²: 0.2169 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"With spatial R²:\", round(summary(model_spatial)$r.squared, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWith spatial R²: 0.3529 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Improvement:\", round(summary(model_spatial)$r.squared - \n                          summary(model_structural)$r.squared, 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nImprovement: 0.136 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n# Part 3: Fixed Effects {background-color=\"#667eea\"}\n\n------------------------------------------------------------------------\n\n## What Are Fixed Effects?\n\n**Fixed Effects** = Categorical variables that capture **all unmeasured\ncharacteristics** of a group\n\n**In hedonic models:**\n\n-   Each neighborhood gets its own dummy variable\n-   Captures everything unique about that neighborhood we didn't\n    explicitly measure\n\n*We technically already did this when I went over categorical data!*\n\n::::: columns\n::: {.column width=\"50%\"}\n**What They Capture:**\n\n-   School quality\n-   \"Prestige\" or reputation\n-   Walkability\n-   Access to jobs\n-   Cultural amenities\n-   Things we **can't easily measure**\n:::\n\n::: {.column width=\"50%\"}\n**The Code:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Add neighborhood fixed effects\nreg5 <- lm(\n  SalePrice ~ LivingArea + Age + \n              crimes_500ft + \n              parks_nn3 + \n              as.factor(name),  # FE\n  data = boston.sf\n)\n```\n:::\n\n\nR creates a dummy for each neighborhood automatically!\n:::\n:::::\n\n------------------------------------------------------------------------\n\n## How Fixed Effects Work\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Behind the scenes, R creates dummies:\n# is_BackBay = 1 if Back Bay, 0 otherwise\n# is_Beacon = 1 if Beacon Hill, 0 otherwise\n# is_Allston = 1 if Allston, 0 otherwise\n# ... (R drops one as reference category)\n```\n:::\n\n\n**Interpretation Example:**\n\n```         \nCoefficients:\n(Intercept)           50000\nLivingArea              150\nnameBack_Bay          85000   ← $85k premium vs. reference\nnameBeacon_Hill      125000   ← $125k premium  \nnameAllston          -15000   ← $15k discount\n```\n\n**Each coefficient = price premium/discount for that neighborhood**\n(holding all else constant)\n\n------------------------------------------------------------------------\n\n## Why Use Fixed Effects?\n\n::::: columns\n::: {.column width=\"50%\"}\n### Dramatically Improve Prediction\n\n```         \nModel Comparison (R²):\n- Structural only:     0.58\n- + Spatial features:  0.67\n- + Fixed Effects:     0.81 ✓\n```\n\n**Why such a big jump?**\n\n-   Neighborhoods bundle many unmeasured factors\n-   School districts\n-   Job access\n-   Amenities\n-   \"Cool factor\"\n:::\n\n::: {.column width=\"50%\"}\n### Coefficients Change\n\n**Crime coefficient:**\n\n-   Without FE: -\\$125/crime\n-   With FE: -\\$85/crime\n\n**Why?**\n\n-   Without FE: captured neighborhood confounders too\n-   With FE: neighborhoods \"absorb\" other differences\n-   Now just the crime effect\n:::\n:::::\n\n**Trade-off:** FE are powerful but they're a **black box** - we don't\nknow WHY Back Bay commands a premium\n\n------------------------------------------------------------------------\n\n## Let's Compare All Our Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Model 3: Structural Only\nreg3 <- lm(SalePrice ~ LivingArea + Age + R_FULL_BTH, \n           data = boston.sf)\n\n# Model 4: Add Spatial Features  \nreg4 <- lm(SalePrice ~ LivingArea + Age + R_FULL_BTH +\n                       crimes_500ft + crime_nn3+ dist_downtown_mi,\n           data = boston.sf)\n\nboston.sf <- boston.sf %>%\n  st_join(nhoods, join = st_intersects)\n\n# Model 5: Add Fixed Effects\nreg5 <- lm(SalePrice ~ LivingArea + Age + R_FULL_BTH +\n                       crimes_500ft + crime_nn3+ dist_downtown_mi +\n                       as.factor(name),\n           data = boston.sf)\nlibrary(stargazer)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nPlease cite as: \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare in-sample fit\nstargazer(reg3, reg4, reg5, type = \"text\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n=========================================================================================================\n                                                         Dependent variable:                             \n                             ----------------------------------------------------------------------------\n                                                              SalePrice                                  \n                                       (1)                      (2)                       (3)            \n---------------------------------------------------------------------------------------------------------\nLivingArea                          148.860***               111.501***                118.107***        \n                                     (21.242)                 (20.077)                  (8.586)          \n                                                                                                         \nAge                                 322.029***                123.069                  212.973***        \n                                     (80.730)                 (75.779)                  (30.508)         \n                                                                                                         \nR_FULL_BTH                        113,372.800***            40,173.330*              50,895.880***       \n                                   (23,735.650)             (22,987.460)              (9,458.101)        \n                                                                                                         \ncrimes_500ft                                                 762.817***               -211.220***        \n                                                              (85.812)                  (42.796)         \n                                                                                                         \ncrime_nn3                                                   2,219.712***               466.580***        \n                                                             (242.880)                 (105.506)         \n                                                                                                         \ndist_downtown_mi                                          -202,215.700***           -103,165.100***      \n                                                            (29,626.430)              (30,260.730)       \n                                                                                                         \nas.factor(name)Back Bay                                                             7,668,782.000***     \n                                                                                     (152,445.600)       \n                                                                                                         \nas.factor(name)Bay Village                                                          1,374,060.000***     \n                                                                                     (225,127.300)       \n                                                                                                         \nas.factor(name)Beacon Hill                                                          1,720,668.000***     \n                                                                                     (101,788.600)       \n                                                                                                         \nas.factor(name)Brighton                                                               -186,898.400       \n                                                                                     (120,211.300)       \n                                                                                                         \nas.factor(name)Charlestown                                                            -99,353.820        \n                                                                                      (92,604.600)       \n                                                                                                         \nas.factor(name)Dorchester                                                           -555,954.300***      \n                                                                                      (85,853.130)       \n                                                                                                         \nas.factor(name)Downtown                                                               216,317.000        \n                                                                                     (226,782.100)       \n                                                                                                         \nas.factor(name)East Boston                                                          -574,986.800***      \n                                                                                      (87,455.850)       \n                                                                                                         \nas.factor(name)Fenway                                                               1,034,562.000***     \n                                                                                     (169,543.800)       \n                                                                                                         \nas.factor(name)Hyde Park                                                            -480,342.800***      \n                                                                                      (93,199.370)       \n                                                                                                         \nas.factor(name)Jamaica Plain                                                         -198,209.800**      \n                                                                                      (87,603.690)       \n                                                                                                         \nas.factor(name)Mattapan                                                             -561,786.900***      \n                                                                                      (90,587.160)       \n                                                                                                         \nas.factor(name)Mission Hill                                                          214,567.100**       \n                                                                                     (101,389.300)       \n                                                                                                         \nas.factor(name)Roslindale                                                           -442,450.500***      \n                                                                                      (89,746.210)       \n                                                                                                         \nas.factor(name)Roxbury                                                              -592,878.500***      \n                                                                                      (88,945.650)       \n                                                                                                         \nas.factor(name)South Boston                                                         -290,863.400***      \n                                                                                      (90,664.580)       \n                                                                                                         \nas.factor(name)South End                                                            1,750,702.000***     \n                                                                                      (98,722.040)       \n                                                                                                         \nas.factor(name)West Roxbury                                                         -380,868.400***      \n                                                                                      (91,694.890)       \n                                                                                                         \nConstant                            50,899.030             199,477.900***            778,604.600***      \n                                   (39,788.170)             (70,002.400)             (100,039.000)       \n                                                                                                         \n---------------------------------------------------------------------------------------------------------\nObservations                          1,485                    1,485                     1,485           \nR2                                    0.152                    0.276                     0.885           \nAdjusted R2                           0.150                    0.273                     0.883           \nResidual Std. Error          557,399.300 (df = 1481)  515,703.200 (df = 1478)   206,473.300 (df = 1460)  \nF Statistic                  88.527*** (df = 3; 1481) 93.739*** (df = 6; 1478) 469.541*** (df = 24; 1460)\n=========================================================================================================\nNote:                                                                         *p<0.1; **p<0.05; ***p<0.01\n```\n\n\n:::\n:::\n\n\n**But in-sample R² can be misleading! We need cross-validation...**\n\n------------------------------------------------------------------------\n\n# Part 5: Cross-Validation (with Categorical Variables) {background-color=\"#667eea\"}\n\n------------------------------------------------------------------------\n\n## CV Recap (From Last Week)\n\n**Three common validation approaches:**\n\n1.  **Train/Test Split** - 80/20 split, simple but unstable\n2.  **k-Fold Cross-Validation** - Split into k folds, train on k-1, test\n    on 1, repeat\n3.  **LOOCV** - Leave one observation out at a time (special case of\n    *k*-fold)\n\n**Today we'll use k-fold CV** to compare our hedonic models\n\n::::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'caret'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code}\nctrl <- trainControl(\n  method = \"cv\",\n  number = 10  # 10-fold CV\n)\n\nmodel_cv <- train(\n  SalePrice ~ LivingArea + Age,\n  data = boston.sf,\n  method = \"lm\",\n  trControl = ctrl\n)\n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n**Why CV?**\n\n-   Tells us how well model predicts NEW data\n-   More honest than in-sample R²\n-   Helps detect overfitting\n:::\n:::::\n\n------------------------------------------------------------------------\n\n## Comparing Models with CV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nctrl <- trainControl(method = \"cv\", number = 10)\n\n# Model 1: Structural\ncv_m1 <- train(\n  SalePrice ~ LivingArea + Age + R_FULL_BTH,\n  data = boston.sf, method = \"lm\", trControl = ctrl\n)\n\n# Model 2: + Spatial\ncv_m2 <- train(\n  SalePrice ~ LivingArea + Age + R_FULL_BTH + crimes_500ft + crime_nn3,\n  data = boston.sf, method = \"lm\", trControl = ctrl\n)\n\n# Model 3: + Fixed Effects (BUT WAIT - there's a (potential) problem!)\ncv_m3 <- train(\n  SalePrice ~ LivingArea + Age + R_FULL_BTH + crimes_500ft + crime_nn3 + \n              as.factor(name),\n  data = boston.sf, method = \"lm\", trControl = ctrl\n)\n\n# Compare\ndata.frame(\n  Model = c(\"Structural\", \"Spatial\", \"Fixed Effects\"),\n  RMSE = c(cv_m1$results$RMSE, cv_m2$results$RMSE, cv_m3$results$RMSE)\n)\n```\n:::\n\n\n------------------------------------------------------------------------\n\n## ⚠️ The Problem: Sparse Categories\n\n### When CV Fails with Categorical Variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# You might see this error:\nError in model.frame.default: \n  factor 'name' has new level 'West End'\n```\n:::\n\n\n**What happened?**\n\n1.  Random split created 10 folds\n2.  All \"West End\" sales ended up in ONE fold (the test fold)\n3.  Training folds never saw \"West End\"\n4.  Model can't predict for a category it never learned\n\n::: callout-important\n### The Issue\n\nWhen neighborhoods have **very few sales** (\\<10), random CV splits can\nput all instances in the same fold, breaking the model.\n:::\n\n------------------------------------------------------------------------\n\n## Check Your Data First!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ALWAYS run this before CV with categorical variables\ncategory_check %\n  st_drop_geometry() %>%\n  count(name) %>%\n  arrange(n)\n\nprint(category_check)\n```\n:::\n\n\n**Typical output:**\n\n```         \nname                n\nWest End            3  ⚠️ Problem!\nBay Village         5  ⚠️ Risky\nLeather District    8  ⚠️ Borderline\nBack Bay           89  ✓ Safe\nSouth Boston      112  ✓ Safe\n```\n\n::: callout-tip\n**Rule of Thumb:** Categories with **n \\< 10** will likely cause CV\nproblems\n:::\n\n------------------------------------------------------------------------\n\n## Solution: Group Small Neighborhoods\n\n**Most practical approach:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Add count column\nboston.sf <- boston.sf %>%\n  add_count(name)\n\n# Step 2: Group small neighborhoods\nboston.sf <- boston.sf %>%\n  mutate(\n    name_cv = if_else(\n      n < 10,                       # If fewer than 10 sales\n      \"Small_Neighborhoods\",        # Group them\n      as.character(name)            # Keep original\n    ),\n    name_cv = as.factor(name_cv)\n  )\n\n# Step 3: Use grouped version in CV\ncv_model_fe <- train(\n  SalePrice ~ LivingArea + Age + crimes_500ft + \n              as.factor(name_cv),   # Use name_cv, not name!\n  data = boston.sf,\n  method = \"lm\",\n  trControl = trainControl(method = \"cv\", number = 10)\n)\n```\n:::\n\n\n**Trade-off:** Lose granularity for small neighborhoods, but avoid CV\ncrashes\n\n------------------------------------------------------------------------\n\n## Alternative: Drop Sparse Categories\n\n**If grouping doesn't make sense:**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Remove neighborhoods with < 10 sales\nneighborhood_counts %\n  st_drop_geometry() %>%\n  count(name)\n\nkeep_neighborhoods %\n  filter(n >= 10) %>%\n  pull(name)\n\nboston_filtered %\n  filter(name %in% keep_neighborhoods)\n\ncat(\"Removed\", nrow(boston.sf) - nrow(boston_filtered), \"observations\")\n```\n:::\n\n\n::: callout-warning\n**Consider carefully:** Which neighborhoods are you excluding? Often\nthose with less data are marginalized communities. Document what you\nremoved and why.\n:::\n\n------------------------------------------------------------------------\n\n## My Recommended Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Check category sizes\nboston.sf %>%\n  st_drop_geometry() %>%\n  count(name) %>%\n  arrange(n) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 19 × 2\n   name              n\n   <chr>         <int>\n 1 Bay Village       1\n 2 Downtown          1\n 3 Fenway            2\n 4 Back Bay          3\n 5 Allston           6\n 6 Brighton          6\n 7 Mission Hill     14\n 8 Beacon Hill      17\n 9 South End        20\n10 Roxbury          63\n11 Charlestown      65\n12 Mattapan         65\n13 South Boston     80\n14 Jamaica Plain   113\n15 Roslindale      142\n16 East Boston     149\n17 Hyde Park       152\n18 West Roxbury    242\n19 Dorchester      344\n```\n\n\n:::\n\n```{.r .cell-code}\n# 2. Group if needed\nboston.sf <- boston.sf %>%\n  add_count(name) %>%\n  mutate(\n    name_cv = if_else(n < 10, \"Small_Neighborhoods\", as.character(name)),\n    name_cv = as.factor(name_cv)\n  )\n\n# 3. Set up CV\nctrl <- trainControl(method = \"cv\", number = 10)\n\n# 4. Use grouped neighborhoods in ALL models with FE\nmodel <- train(\n  SalePrice ~ LivingArea + Age + crimes_500ft + as.factor(name_cv),\n  data = boston.sf,\n  method = \"lm\",\n  trControl = ctrl\n)\n\n# 5. Report\ncat(\"10-fold CV RMSE:\", round(model$results$RMSE, 0), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n10-fold CV RMSE: 355347 \n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Full Model Comparison with CV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# Prep data\nboston.sf <- boston.sf %>%\n  add_count(name) %>%\n  mutate(name_cv = if_else(n < 10, \"Small_Neighborhoods\", as.character(name)),\n         name_cv = as.factor(name_cv))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStoring counts in `nn`, as `n` already present in input\nℹ Use `name = \"new_name\"` to pick a new name.\n```\n\n\n:::\n\n```{.r .cell-code}\nctrl <- trainControl(method = \"cv\", number = 10)\n\n# Compare models\ncv_structural <- train(\n  SalePrice ~ LivingArea + Age + R_FULL_BTH,\n  data = boston.sf, method = \"lm\", trControl = ctrl\n)\n\ncv_spatial <- train(\n  SalePrice ~ LivingArea + Age + R_FULL_BTH + crimes_500ft + crime_nn3,\n  data = boston.sf, method = \"lm\", trControl = ctrl\n)\n\ncv_fixedeffects <- train(\n  SalePrice ~ LivingArea + Age + R_FULL_BTH + crimes_500ft + crime_nn3 + \n              as.factor(name_cv),\n  data = boston.sf, method = \"lm\", trControl = ctrl\n)\n\n# Results\ndata.frame(\n  Model = c(\"Structural\", \"+ Spatial\", \"+ Fixed Effects\"),\n  RMSE = c(cv_structural$results$RMSE, \n           cv_spatial$results$RMSE, \n           cv_fixedeffects$results$RMSE)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Model     RMSE\n1      Structural 535132.8\n2       + Spatial 508962.7\n3 + Fixed Effects 348169.2\n```\n\n\n:::\n:::\n\n\n------------------------------------------------------------------------\n\n## Expected Results\n\n**Typical pattern:**\n\n```         \nModel              RMSE      Interpretation\nStructural        $533,330.60   Baseline - just house characteristics\n+ Spatial         $500,421.5    Adding location features helps!\n+ Fixed Effects   $347,261.30   Neighborhoods capture a LOT\n```\n\n*Note: these values are kind of ginormous - remember RMSE squares big\nerrors, so outliers can have a really large impact*\n\n**Key Insight:** Each layer improves **out-of-sample** prediction, with\nfixed effects providing the biggest boost\n\n**Why?** Neighborhoods bundle many unmeasured factors (schools,\namenities, prestige) that we can't easily quantify individually\n\n------------------------------------------------------------------------\n\n## Investigating those errors...\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n       0   417500   519000   647981   650000 11600000 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 3\n   SalePrice LivingArea name       \n       <dbl>      <dbl> <chr>      \n 1  11600000       9908 Back Bay   \n 2   9500000       5283 Back Bay   \n 3   6350000       4765 Back Bay   \n 4   4600000       3018 Beacon Hill\n 5   4300000       3981 South End  \n 6   4274500       5439 Beacon Hill\n 7   4200000       4146 South End  \n 8   3900000       4396 Beacon Hill\n 9   3877500       3849 Beacon Hill\n10   3810000       4449 Beacon Hill\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](week-06-class-lab_files/figure-html/unnamed-chunk-52-2.png){width=672}\n:::\n:::\n\n\n**Look for:** - Prices over \\$2-3 million (could be luxury condos or\nerrors) - Prices near \\$0 (data errors) - Long right tail in histogram\n\n------------------------------------------------------------------------\n\n# What to Do?\n\n**Log Transform the skewed dependent variable**\n\n::: callout-note\n### Interpreting Log Models\n\n-   RMSE is now in **log-dollars** (hard to interpret)\n-   To convert back: `exp(predictions)` gives actual dollars\n-   Coefficients now represent **percentage changes**, not dollar\n    changes\n-   This is standard practice in hedonic modeling!\n:::\n\n---\n## 🎯 Final Team Exercise (Remaining Class Time)\n---\n\n## Team Exercise: Practice What We've Done and Build Your Best Model\n\n**Goal:** Create a comprehensive hedonic model using ALL concepts from\ntoday (and last week)\n\n**Requirements:**\n\n1.  Structural variables (including categorical)\n2.  Spatial features (create your own -\n    nhttps://data.boston.gov/group/geospatial\n3.  At least one interaction term\n4.  One non-linear (polynomial term)\n5.  Neighborhood fixed effects (handle sparse categories!)\n6.  10-fold cross-validation\n7.  Report final RMSE\n\n## *Use diagnostics from last week as you build!*\n\n## Report Out on Board\n\n**Each team will share (3 minutes):**\n\n1.  **Variables used:**\n\n    -   Structural: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n    -   Spatial: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n    -   Non-linear: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n    -   Interactions: \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n    -   Fixed Effects: Yes/No, how handled sparse categories?\n\n2.  **Final cross-validated RMSE:** \\$\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ and\n    **MAE** \\$\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n3.  **One insight:**\n\n    -   What made the biggest difference?\n    -   Did anything surprise you?\n    -   Which variables mattered most?\n\n------------------------------------------------------------------------\n\n## Tips for Success\n\n::::: columns\n::: {.column width=\"50%\"}\n### ✅ Do:\n\n-   Start simple, add complexity\n-   Check for NAs: `sum(is.na())`\n-   Test on small subset first\n-   Comment your code\n-   Check coefficient signs\n-   Use `glimpse()`, `summary()`\n\n### ❌ Don't:\n\n-   Add 50 variables at once\n-   Ignore errors\n-   Forget `st_drop_geometry()` for non-spatial operations\n-   Skip sparse category check\n:::\n\n::: {.column width=\"50%\"}\n### Common Errors\n\n**\"Factor has new levels\"** → Group sparse categories\n\n**\"Computationally singular\"** → Remove collinear variables\n\n**Very high RMSE** → Check outliers, scale\n\n**CV takes forever** → Simplify model or reduce folds\n\n**Negative R²** → Model worse than mean, rethink variables\n:::\n:::::\n\n------------------------------------------------------------------------\n",
    "supporting": [
      "week-06-class-lab_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}